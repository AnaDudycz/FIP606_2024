[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Olá, seja bem-vindo(a) ao meu website!",
    "section": "",
    "text": "LinkedIn\n  \n  \n    \n     Githube\n  \n  \n    \n     Email\n  \n\n\n\n\nOlá, seja bem-vindo(a) ao meu website!\nMe chamo Ana Rita Dudycz, sou engenheira agrônoma pela Universidade Estadual do Centro-Oeste (UNICENTRO) e mestranda em fitopatologia na Universidade Federal de Viçosa (UFV).\nAqui você vai encontrar o material com anotações da disciplina análise e visualização de dados em fitopatologia, ofertada pelo Programa de Pós-Graduação em Fitopatologia da UFV.\nAproveite o conteúdo! Qualquer dúvida pode entrar em contato pelo meu e-mail."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Aula1.html",
    "href": "Aula1.html",
    "title": "Introdução ao R",
    "section": "",
    "text": "No programa R podemos inserir anotações e formatar o documento como um documento de texto. Para colocar uma palavra em negrito adiciona-se dois asteriscos antes e após a palavra (** **), e um anterisco antes e após a palavra (* *), para colocar uma palavra em itálico. O tamanho da fonte pode ser regulada pela quantidade de #."
  },
  {
    "objectID": "Aula1.html#aprendendo-como-inserir-texto-ou-códigos-no-r",
    "href": "Aula1.html#aprendendo-como-inserir-texto-ou-códigos-no-r",
    "title": "Introdução ao R",
    "section": "",
    "text": "No programa R podemos inserir anotações e formatar o documento como um documento de texto. Para colocar uma palavra em negrito adiciona-se dois asteriscos antes e após a palavra (** **), e um anterisco antes e após a palavra (* *), para colocar uma palavra em itálico. O tamanho da fonte pode ser regulada pela quantidade de #."
  },
  {
    "objectID": "Aula1.html#r-markdown",
    "href": "Aula1.html#r-markdown",
    "title": "Introdução ao R",
    "section": "R markdown",
    "text": "R markdown\nFormato que permite trabalhar com chunks separados e fazer o uso de anotações entre os mesmos. Pode-se inserir anotações úteis na análise do projeto. Um chunk é a área onde os códigos são inseridos e é possível rodar as análises. Para adicionar um chunk pode-se clicar em Ctrl+Alt+I.\n\nx &lt;- 10\ny &lt;- x * 10 \nz &lt;- x * y\nx &lt;- 10"
  },
  {
    "objectID": "Aula1.html#data.frame",
    "href": "Aula1.html#data.frame",
    "title": "Introdução ao R",
    "section": "Data.Frame",
    "text": "Data.Frame\nA função data.frame pode ser usada para organizar os dados trabalhados em uma tabela.\n\ndf &lt;- cars\ncars\n\n   speed dist\n1      4    2\n2      4   10\n3      7    4\n4      7   22\n5      8   16\n6      9   10\n7     10   18\n8     10   26\n9     10   34\n10    11   17\n11    11   28\n12    12   14\n13    12   20\n14    12   24\n15    12   28\n16    13   26\n17    13   34\n18    13   34\n19    13   46\n20    14   26\n21    14   36\n22    14   60\n23    14   80\n24    15   20\n25    15   26\n26    15   54\n27    16   32\n28    16   40\n29    17   32\n30    17   40\n31    17   50\n32    18   42\n33    18   56\n34    18   76\n35    18   84\n36    19   36\n37    19   46\n38    19   68\n39    20   32\n40    20   48\n41    20   52\n42    20   56\n43    20   64\n44    22   66\n45    23   54\n46    24   70\n47    24   92\n48    24   93\n49    24  120\n50    25   85\n\ndf$dist\n\n [1]   2  10   4  22  16  10  18  26  34  17  28  14  20  24  28  26  34  34  46\n[20]  26  36  60  80  20  26  54  32  40  32  40  50  42  56  76  84  36  46  68\n[39]  32  48  52  56  64  66  54  70  92  93 120  85\n\ndf$dist2 &lt;- c(1:50)\n\nlibrary(tidyverse)\n\ndf |&gt; \n  mutate(dist3 = dist2+1) |&gt; \n  select(4)\n\n   dist3\n1      2\n2      3\n3      4\n4      5\n5      6\n6      7\n7      8\n8      9\n9     10\n10    11\n11    12\n12    13\n13    14\n14    15\n15    16\n16    17\n17    18\n18    19\n19    20\n20    21\n21    22\n22    23\n23    24\n24    25\n25    26\n26    27\n27    28\n28    29\n29    30\n30    31\n31    32\n32    33\n33    34\n34    35\n35    36\n36    37\n37    38\n38    39\n39    40\n40    41\n41    42\n42    43\n43    44\n44    45\n45    46\n46    47\n47    48\n48    49\n49    50\n50    51"
  },
  {
    "objectID": "Aula1.html#instalando-pacotes",
    "href": "Aula1.html#instalando-pacotes",
    "title": "Introdução ao R",
    "section": "Instalando pacotes",
    "text": "Instalando pacotes\nHá diferentes formas de instalar pacotes. No source pode-se escrever o código Install.packages(“nome do pacote”). Para utilizar o pacote é necessário carregar o pacote com a função library(nome do pacote)\n\ninstall.packages(\"tidyverse\")\nlibrary(tidyverse)"
  },
  {
    "objectID": "Aula1.html#utilizando-o-pacote-ec50estimator",
    "href": "Aula1.html#utilizando-o-pacote-ec50estimator",
    "title": "Introdução ao R",
    "section": "Utilizando o pacote ec50estimator",
    "text": "Utilizando o pacote ec50estimator\nCom o pacote ec50estimator pode-se estimar a dose efetiva a partir de um conjunto de dados. Pode -se observar um exemplo chamado multi_isolate dentro do pacote, em que há um conjunto de dados relacionando o crescimento micelial a partir de diferentes doses de fungicidas.\n\n##install.packages(\"ec50estimator\")\nlibrary (ec50estimator)\ndf1 &lt;- multi_isolate"
  },
  {
    "objectID": "Aula3.html",
    "href": "Aula3.html",
    "title": "Gráficos com ggplot",
    "section": "",
    "text": "Com o pacote ggplot2 e a função ggploté possivel criar gráficos a partir da planilha carregada anteriormente. Com este pacote é possível escolher o tipo de gráfico como o geom_boxplot no exemplo abaixo e personalizar da maneira desejada, com comandos e argumentos necessários, pode-se ajusta a cor, distâncias e tamanho das linhas e barras, adicionar legenda e formatar os eixos. Para salvar o gráfico gerado a função ggsave pode ser utilizada.\n\nlibrary(gsheet)\ndf4 &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=983033137#gid=983033137\")\n\nlibrary(ggplot2)\nlibrary(ggthemes)\ng1 &lt;- df4 |&gt; \n  ggplot(aes(x = trat, y = comp)) +\n  geom_boxplot(outlier.colour = NA,\n               fill = \"green\")+\n  geom_jitter(width = 0.05,\n              color = 'black',\n              shape = 2,\n              size = 3)+\n  theme_clean()+\n  labs (x = \"tratamento\",\n       y = \"comprimento (mm)\",\n       title = \"Meu primeiro ggplot\",\n       caption = \"Fonte: Dados diversos\")\ng1\n\n\n\n#ylim(0,20)+\n  scale_y_continuous(limits = c(5,20),\n                     n.breaks =10)\n\n&lt;ScaleContinuousPosition&gt;\n Range:  \n Limits:    5 --   20\n\n  ggsave(\"plot1.png\", bg = \"white\")"
  },
  {
    "objectID": "Aula3.html#constução-de-gráficos",
    "href": "Aula3.html#constução-de-gráficos",
    "title": "Gráficos com ggplot",
    "section": "",
    "text": "Com o pacote ggplot2 e a função ggploté possivel criar gráficos a partir da planilha carregada anteriormente. Com este pacote é possível escolher o tipo de gráfico como o geom_boxplot no exemplo abaixo e personalizar da maneira desejada, com comandos e argumentos necessários, pode-se ajusta a cor, distâncias e tamanho das linhas e barras, adicionar legenda e formatar os eixos. Para salvar o gráfico gerado a função ggsave pode ser utilizada.\n\nlibrary(gsheet)\ndf4 &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=983033137#gid=983033137\")\n\nlibrary(ggplot2)\nlibrary(ggthemes)\ng1 &lt;- df4 |&gt; \n  ggplot(aes(x = trat, y = comp)) +\n  geom_boxplot(outlier.colour = NA,\n               fill = \"green\")+\n  geom_jitter(width = 0.05,\n              color = 'black',\n              shape = 2,\n              size = 3)+\n  theme_clean()+\n  labs (x = \"tratamento\",\n       y = \"comprimento (mm)\",\n       title = \"Meu primeiro ggplot\",\n       caption = \"Fonte: Dados diversos\")\ng1\n\n\n\n#ylim(0,20)+\n  scale_y_continuous(limits = c(5,20),\n                     n.breaks =10)\n\n&lt;ScaleContinuousPosition&gt;\n Range:  \n Limits:    5 --   20\n\n  ggsave(\"plot1.png\", bg = \"white\")"
  },
  {
    "objectID": "Aula3.html#importando-os-dados-com-o-pacote-tidyverse",
    "href": "Aula3.html#importando-os-dados-com-o-pacote-tidyverse",
    "title": "Gráficos com ggplot",
    "section": "Importando os dados com o pacote tidyverse",
    "text": "Importando os dados com o pacote tidyverse\n\nlibrary(tidyverse)\ncr &lt;- read_csv(\"https://raw.githubusercontent.com/emdelponte/paper-coffee-rust-Ethiopia/master/data/survey_clean.csv\")\n\nglimpse(cr)\n\nRows: 405\nColumns: 13\n$ farm            &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,…\n$ region          &lt;chr&gt; \"SNNPR\", \"SNNPR\", \"SNNPR\", \"SNNPR\", \"SNNPR\", \"SNNPR\", …\n$ zone            &lt;chr&gt; \"Bench Maji\", \"Bench Maji\", \"Bench Maji\", \"Bench Maji\"…\n$ district        &lt;chr&gt; \"Debub Bench\", \"Debub Bench\", \"Debub Bench\", \"Debub Be…\n$ lon             &lt;dbl&gt; 35.44250, 35.44250, 35.42861, 35.42861, 35.42861, 35.3…\n$ lat             &lt;dbl&gt; 6.904722, 6.904722, 6.904444, 6.904444, 6.904444, 6.90…\n$ altitude        &lt;dbl&gt; 1100, 1342, 1434, 1100, 1400, 1342, 1432, 1100, 1400, …\n$ cultivar        &lt;chr&gt; \"Local\", \"Mixture\", \"Mixture\", \"Local\", \"Local\", \"Mixt…\n$ shade           &lt;chr&gt; \"Sun\", \"Mid shade\", \"Mid shade\", \"Sun\", \"Sun\", \"Mid sh…\n$ cropping_system &lt;chr&gt; \"Plantation\", \"Plantation\", \"Plantation\", \"Plantation\"…\n$ farm_management &lt;chr&gt; \"Unmanaged\", \"Minimal\", \"Minimal\", \"Unmanaged\", \"Unman…\n$ inc             &lt;dbl&gt; 86.70805, 51.34354, 43.20000, 76.70805, 47.15808, 51.3…\n$ sev2            &lt;dbl&gt; 55.57986, 17.90349, 8.25120, 46.10154, 12.25167, 19.91…"
  },
  {
    "objectID": "Aula3.html#trabalhando-os-dados",
    "href": "Aula3.html#trabalhando-os-dados",
    "title": "Gráficos com ggplot",
    "section": "Trabalhando os dados",
    "text": "Trabalhando os dados\nPara visualizar os dados do conjunto chamado cr, os dados foram agrupados com a função group_by(), posteriormente Calculada a média com o comando mean(), os resultados visualizados com ggplot.\n\nsummary(cr$inc)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   9.50   19.43   32.50   34.89   48.20   86.71 \n\ncr |&gt;\n  group_by(cultivar) |&gt;\n    summarize(inc_mean = mean(inc),\nsd_mean = sd(inc))\n\n# A tibble: 3 × 3\n  cultivar inc_mean sd_mean\n  &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;\n1 Improved     16.4    5.66\n2 Local        53.4   14.3 \n3 Mixture      31.9   11.2 \n\ncr |&gt;\n  ggplot(aes(x=inc))+\n  geom_histogram()+\n  facet_grid(region~cultivar)"
  },
  {
    "objectID": "Aula3.html#usando-as-funções-para-sumarizar",
    "href": "Aula3.html#usando-as-funções-para-sumarizar",
    "title": "Gráficos com ggplot",
    "section": "Usando as funções para sumarizar",
    "text": "Usando as funções para sumarizar\nA função summarize () é utilizada para criar novas variáveis a partir do conjunto de dados já agrupados.\n\ncr |&gt;\n group_by(region) |&gt;\n    summarize(sev_med = median(sev2),\n              sev_mean = mean(sev2),\n              sev_sd = sd(sev2))\n\n# A tibble: 2 × 4\n  region sev_med sev_mean sev_sd\n  &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n1 Oromia    6.23     8.06   6.82\n2 SNNPR     4.88     9.81  10.5 \n\ncr |&gt;\n  ggplot(aes(inc,sev2))+\n  geom_point()"
  },
  {
    "objectID": "Aula3.html#visualizando-os-dados",
    "href": "Aula3.html#visualizando-os-dados",
    "title": "Gráficos com ggplot",
    "section": "Visualizando os dados",
    "text": "Visualizando os dados\n\nlibrary(ggthemes)\ncr |&gt;\n  ggplot(aes(x =sev2, fill = region))+\n  geom_histogram(color = \"white\")+\n  facet_wrap(region ~ cultivar, ncol = 6)+\n  scale_fill_manual(values = c(\"black\", \"brown\"))+\n  theme_minimal(base_size = 14)+\n  theme(legend.position = \"bottom\")+\n  labs(y = \"Frequency\",\n       x = \"Severity (%)\", fill= \"Region\")\n\n\n\n#ggsave(\"crl.png\", bg = \"white\")"
  },
  {
    "objectID": "Aula3.html#criando-subconjuntos",
    "href": "Aula3.html#criando-subconjuntos",
    "title": "Gráficos com ggplot",
    "section": "Criando subconjuntos",
    "text": "Criando subconjuntos\nO pacote dplyr possui funções que ajudam na manipulação dos dados e facilitam a visualização, como a função select() que seleciona as coluna de um dataframe e a função filter() que permite-se fazer a filtragem das linhas do conjunto.\n\n# filtra Oromia\ncr_oromia &lt;- cr |&gt;\n  select(farm, region, cultivar, sev2) |&gt;\n  filter(region == \"Oromia\")\n\n# filtra SNNPR\ncr_pr &lt;- cr|&gt;\n  select(farm, region, cultivar, sev2) |&gt;\n  filter(region == \"SNNPR\")\n\ncr_pr\n\n# A tibble: 240 × 4\n    farm region cultivar  sev2\n   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;\n 1     1 SNNPR  Local    55.6 \n 2     2 SNNPR  Mixture  17.9 \n 3     3 SNNPR  Mixture   8.25\n 4     4 SNNPR  Local    46.1 \n 5     5 SNNPR  Local    12.3 \n 6     6 SNNPR  Mixture  19.9 \n 7     7 SNNPR  Mixture  11.9 \n 8     8 SNNPR  Local    55.6 \n 9     9 SNNPR  Local    11.6 \n10    10 SNNPR  Mixture  11.4 \n# ℹ 230 more rows"
  },
  {
    "objectID": "Aula3.html#visualizando-os-subconjuntos",
    "href": "Aula3.html#visualizando-os-subconjuntos",
    "title": "Gráficos com ggplot",
    "section": "Visualizando os subconjuntos",
    "text": "Visualizando os subconjuntos\n\np1 &lt;- cr_oromia |&gt;\n  ggplot(aes(cultivar, sev2,\n             fill = cultivar))+\n  geom_boxplot()+\n  theme_few()+\n  scale_fill_few()+\n  labs(x = \"\",\n       y = \"Severity (%)\")+\n    coord_flip()\n\np2 &lt;- cr_pr |&gt;\n  ggplot(aes(cultivar, sev2,\n             fill = cultivar))+\n  geom_boxplot()+\n  theme_few()+\n  scale_fill_few()+\n  labs(x = \"\",\n       y = \"Severity (%)\")+\n    coord_flip()\n\np1\n\n\n\np2\n\n\n\nlibrary(patchwork)\n\np1 + p2 +\n  plot_layout(guides = 'collect',\n  axes = 'collect')+\n  plot_annotation(title = \"Coffe rust in Ethiopia\",\n                  caption = \"Source: Dudycz (2024)\")\n\n\n\n  plot_annotation(tag_levels = 'A')\n\n$title\nNULL\n\n$subtitle\nNULL\n\n$caption\nNULL\n\n$tag_levels\n[1] \"A\"\n\n$tag_prefix\nNULL\n\n$tag_suffix\nNULL\n\n$tag_sep\nNULL\n\n$theme\n Named list()\n - attr(*, \"class\")= chr [1:2] \"theme\" \"gg\"\n - attr(*, \"complete\")= logi FALSE\n - attr(*, \"validate\")= logi TRUE\n\nattr(,\"class\")\n[1] \"plot_annotation\"\n\nggsave(\"patch1.png\", width = 6,\n       height = 4)\n\np3 &lt;- cr_oromia |&gt;\n  ggplot(aes(x = sev2))+\n  geom_histogram()\n\np1 + inset_element(p3, left = 0.6, bottom = 0.6, right = 1, top = 1)\n\n\n\np1/ (p2 + p1)"
  },
  {
    "objectID": "Aula2.html",
    "href": "Aula2.html",
    "title": "Formas de carregar planilhas para dentro do R",
    "section": "",
    "text": "Primeiramente é necessário adicionar a planilha com os dados, dentro da pasta com o projeto de trabalho. Em seguida instalar e carregar o pacote readxl. Para corregar a planilha é necessário usar a função read_excel() e inserir o nome completo do arquivo incluindo o .xlsx, entre aspas. Se houver mais de uma planilha dentro do arquivo excel é necessário indicar qual a planilha deseja-se adicionar, deve-se adicionar o argumento sheet = número da ordem da planilha.\n\n##install.packages(\"readxl\")\nlibrary(readxl)\n\ndf2 &lt;- read_excel(\"dados-diversos.xlsx\")\ndf21 &lt;- read_excel(\"dados-diversos.xlsx\", sheet = 2)"
  },
  {
    "objectID": "Aula2.html#abrindo-conjunto-de-dados-a-partir-de-uma-planilha-excel",
    "href": "Aula2.html#abrindo-conjunto-de-dados-a-partir-de-uma-planilha-excel",
    "title": "Formas de carregar planilhas para dentro do R",
    "section": "",
    "text": "Primeiramente é necessário adicionar a planilha com os dados, dentro da pasta com o projeto de trabalho. Em seguida instalar e carregar o pacote readxl. Para corregar a planilha é necessário usar a função read_excel() e inserir o nome completo do arquivo incluindo o .xlsx, entre aspas. Se houver mais de uma planilha dentro do arquivo excel é necessário indicar qual a planilha deseja-se adicionar, deve-se adicionar o argumento sheet = número da ordem da planilha.\n\n##install.packages(\"readxl\")\nlibrary(readxl)\n\ndf2 &lt;- read_excel(\"dados-diversos.xlsx\")\ndf21 &lt;- read_excel(\"dados-diversos.xlsx\", sheet = 2)"
  },
  {
    "objectID": "Aula2.html#abrindo-conjunto-de-dados-a-partir-de-um-arquivo-de-texto-csv",
    "href": "Aula2.html#abrindo-conjunto-de-dados-a-partir-de-um-arquivo-de-texto-csv",
    "title": "Formas de carregar planilhas para dentro do R",
    "section": "Abrindo conjunto de dados a partir de um arquivo de texto (csv)",
    "text": "Abrindo conjunto de dados a partir de um arquivo de texto (csv)\nO processo é o mesmo do arquivo xlsx, basta adicionar o aquivo no formato csv na pasta do projeto. O pacote a ser usado é o tidyverse e a função read.csv().\n\nlibrary(tidyverse)\ndf3 &lt;- read.csv(\"dados-diversos.csv\")"
  },
  {
    "objectID": "Aula2.html#abrindo-conjunto-de-dados-a-partir-de-uma-planilha-google",
    "href": "Aula2.html#abrindo-conjunto-de-dados-a-partir-de-uma-planilha-google",
    "title": "Formas de carregar planilhas para dentro do R",
    "section": "Abrindo conjunto de dados a partir de uma planilha google",
    "text": "Abrindo conjunto de dados a partir de uma planilha google\nCom o pacote gsheet e a função gsheet2tbl é possivel carregar uma planilha google apenas com o link desta.Também é possível fazer o carregamento com o pacote googlesheets4 e a função read_sheet.\n\nlibrary(gsheet)\ndf4 &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit?gid=983033137#gid=983033137\")"
  },
  {
    "objectID": "Aula4.html",
    "href": "Aula4.html",
    "title": "Outros pacotes e funções na construção de gráficos",
    "section": "",
    "text": "O vetor ‘comp’ que contém 20 valores numéricos representando a concentração do composto em diferentes experimentos. O objeto data.table em R armazena os dados experimentais sobre a concentração de um composto (comp) em diferentes tratamentos (trat) e repetições (rep).\n\ncomp &lt;- (c(9, 12.5, 10, 8, 13.2, 11, 10.8, 9.5, 10.8, 10.4, 13.72, 15.91, 15.7, 14.2, 15.9, 16.54, 18, 14.4, 16.41, 16)\n)\n\ndata.table::data.table(\n        trat = c(\"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\n                 \"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\"control\",\"control\",\"control\",\n                 \"control\",\"control\",\"control\",\"control\",\"control\",\"control\",\n                 \"control\"),\n         rep = c(1L,2L,3L,4L,5L,6L,7L,8L,9L,10L,1L,\n                 2L,3L,4L,5L,6L,7L,8L,9L,10L),\n        comp = c(9,12.5,10,8,13.2,11,10.8,9.5,10.8,\n                 10.4,13.72,15.91,15.7,14.2,15.9,16.54,18,14.4,16.41,\n                 16)\n)\n\n       trat   rep  comp\n     &lt;char&gt; &lt;int&gt; &lt;num&gt;\n 1:     Mg2     1  9.00\n 2:     Mg2     2 12.50\n 3:     Mg2     3 10.00\n 4:     Mg2     4  8.00\n 5:     Mg2     5 13.20\n 6:     Mg2     6 11.00\n 7:     Mg2     7 10.80\n 8:     Mg2     8  9.50\n 9:     Mg2     9 10.80\n10:     Mg2    10 10.40\n11: control     1 13.72\n12: control     2 15.91\n13: control     3 15.70\n14: control     4 14.20\n15: control     5 15.90\n16: control     6 16.54\n17: control     7 18.00\n18: control     8 14.40\n19: control     9 16.41\n20: control    10 16.00\n       trat   rep  comp"
  },
  {
    "objectID": "Aula4.html#usando-datapasta-de-dados-a-partir-de-uma-tabela-google",
    "href": "Aula4.html#usando-datapasta-de-dados-a-partir-de-uma-tabela-google",
    "title": "Outros pacotes e funções na construção de gráficos",
    "section": "",
    "text": "O vetor ‘comp’ que contém 20 valores numéricos representando a concentração do composto em diferentes experimentos. O objeto data.table em R armazena os dados experimentais sobre a concentração de um composto (comp) em diferentes tratamentos (trat) e repetições (rep).\n\ncomp &lt;- (c(9, 12.5, 10, 8, 13.2, 11, 10.8, 9.5, 10.8, 10.4, 13.72, 15.91, 15.7, 14.2, 15.9, 16.54, 18, 14.4, 16.41, 16)\n)\n\ndata.table::data.table(\n        trat = c(\"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\n                 \"Mg2\",\"Mg2\",\"Mg2\",\"Mg2\",\"control\",\"control\",\"control\",\n                 \"control\",\"control\",\"control\",\"control\",\"control\",\"control\",\n                 \"control\"),\n         rep = c(1L,2L,3L,4L,5L,6L,7L,8L,9L,10L,1L,\n                 2L,3L,4L,5L,6L,7L,8L,9L,10L),\n        comp = c(9,12.5,10,8,13.2,11,10.8,9.5,10.8,\n                 10.4,13.72,15.91,15.7,14.2,15.9,16.54,18,14.4,16.41,\n                 16)\n)\n\n       trat   rep  comp\n     &lt;char&gt; &lt;int&gt; &lt;num&gt;\n 1:     Mg2     1  9.00\n 2:     Mg2     2 12.50\n 3:     Mg2     3 10.00\n 4:     Mg2     4  8.00\n 5:     Mg2     5 13.20\n 6:     Mg2     6 11.00\n 7:     Mg2     7 10.80\n 8:     Mg2     8  9.50\n 9:     Mg2     9 10.80\n10:     Mg2    10 10.40\n11: control     1 13.72\n12: control     2 15.91\n13: control     3 15.70\n14: control     4 14.20\n15: control     5 15.90\n16: control     6 16.54\n17: control     7 18.00\n18: control     8 14.40\n19: control     9 16.41\n20: control    10 16.00\n       trat   rep  comp"
  },
  {
    "objectID": "Aula4.html#dados-a-partir-da-web",
    "href": "Aula4.html#dados-a-partir-da-web",
    "title": "Outros pacotes e funções na construção de gráficos",
    "section": "Dados a partir da web",
    "text": "Dados a partir da web\nA função tribble() do pacote tibble também pode ser usada para organizar os dados em uma tabela.\n\ntibble::tribble(\n  ~`1`,          ~Brazil, ~`4,303`,\n    2L,     \"Mozambique\",      43L,\n    3L,       \"Portugal\",      33L,\n    4L,  \"United States\",      23L,\n    5L,         \"Angola\",      19L,\n    6L,          \"Spain\",      16L,\n    7L,      \"(not set)\",      12L,\n    8L,       \"Colombia\",       8L,\n    9L,        \"Germany\",       5L,\n   10L,        \"Hungary\",       5L,\n   11L, \"United Kingdom\",       5L,\n   12L,    \"Netherlands\",       4L,\n   13L,        \"Ecuador\",       3L,\n   14L,         \"France\",       3L,\n   15L,          \"Chile\",       2L,\n   16L,       \"Paraguay\",       2L,\n   17L,           \"Peru\",       2L,\n   18L,      \"Argentina\",       1L,\n   19L,        \"Austria\",       1L,\n   20L,        \"Bolivia\",       1L,\n   21L,     \"Cape Verde\",       1L,\n   22L,          \"China\",       1L,\n   23L,          \"Egypt\",       1L,\n   24L,        \"Finland\",       1L,\n   25L,          \"India\",       1L,\n   26L,          \"Italy\",       1L,\n   27L,       \"Malaysia\",       1L,\n   28L,       \"Pakistan\",       1L,\n   29L,         \"Poland\",       1L,\n   30L,      \"Singapore\",       1L,\n   31L,    \"Timor-Leste\",       1L,\n   32L,        \"Uruguay\",       1L\n  )\n\n# A tibble: 31 × 3\n     `1` Brazil         `4,303`\n   &lt;int&gt; &lt;chr&gt;            &lt;int&gt;\n 1     2 Mozambique          43\n 2     3 Portugal            33\n 3     4 United States       23\n 4     5 Angola              19\n 5     6 Spain               16\n 6     7 (not set)           12\n 7     8 Colombia             8\n 8     9 Germany              5\n 9    10 Hungary              5\n10    11 United Kingdom       5\n# ℹ 21 more rows\n\n\nO pacote tiyverse pode ser usado para a remodelagem dos dados. A função pivot_longer() permite passar os dados do formato largo para o formato longo. A função annotate do pacote ggplot2 em R é usada para adicionar anotações personalizadas aos gráficos, como textos para destacar ou explicar partes específicas de um gráfico.\n\nlibrary(tidyverse)\npepper &lt;- \n  tribble(\n   ~t,  ~`1`,  ~`2`,  ~`3`,\n   0,  0.08, 0.001, 0.001,\n   7,  0.13,  0.01, 0.001,\n  14,  0.78,  0.09,  0.01,\n  21,  0.92,  0.25,  0.05,\n  28,  0.99,   0.8,  0.18,\n  35, 0.995,  0.98,  0.34,\n  42, 0.999,  0.99,  0.48,\n  49, 0.999, 0.999,  0.74\n  )\n\npepper |&gt; \n  pivot_longer(2:4,\n               names_to = \"epidemic\",\n               values_to = \"inc\") |&gt;\n  ggplot(aes(t, inc, color = epidemic)) +\n  geom_point() +\n  geom_line() +\n  annotate(geom = \"text\",\n           x = 12,\n           y = 0.75,\n           label =\"1\")+\n annotate(geom = \"text\",\n           x = 25,\n           y = 0.75,\n           label =\"2\")+\n   annotate(geom = \"text\",\n           x = 47,\n           y = 0.75,\n           label =\"3\")+\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "Aula4.html#tabela-de-contingência",
    "href": "Aula4.html#tabela-de-contingência",
    "title": "Outros pacotes e funções na construção de gráficos",
    "section": "Tabela de contingência",
    "text": "Tabela de contingência\nUma tabela de contingência é uma forma de resumir e visualizar a distribuição conjunta de duas ou mais variáveis categóricas. Ela mostra como as frequências ou contagens são distribuídas entre as diferentes categorias de cada uma das variáveis, permitindo analisar relações e associações entre elas.\no conjunto de dados cr que foi lido do arquivo CSV e usar o pacote janitor para criar uma tabela de contingência e ggplot2 para criar gráficos.\ncriou-se uma tabela de contingência para as variáveis cultivar e farm_management usando tabyl.\n\nlibrary(ggthemes)\ncr &lt;- read_csv(\"https://raw.githubusercontent.com/emdelponte/paper-coffee-rust-Ethiopia/master/data/survey_clean.csv\")\n\ncr |&gt;\n  count(farm_management, cultivar) |&gt;\n  ggplot(aes(cultivar, n, fill = farm_management,\n             label = n)) +\n  geom_col(position = \"dodge2\")+\n  scale_fill_colorblind()+\n  theme_bw()+\n  theme(strip.text.x=element_blank(),\n        legend.position = \"top\")+\n  geom_text(position = position_dodge(width = 0.9))+\n  facet_wrap(~cultivar, scales = \"free_x\")\n\n\n\nlibrary(janitor)\n\ncr |&gt;\n  tabyl(cultivar, farm_management)\n\n cultivar Intensive Minimal Moderate Unmanaged\n Improved        83       0        0         0\n    Local         0      10        4       102\n  Mixture        82      59       65         0"
  },
  {
    "objectID": "Aula4.html#geom_errorbar",
    "href": "Aula4.html#geom_errorbar",
    "title": "Outros pacotes e funções na construção de gráficos",
    "section": "geom_errorbar",
    "text": "geom_errorbar\nO geom_errorbar() é uma função do pacote ggplot2 que permite adicionar barras de erro a um gráfico. Essas barras de erro são frequentemente usadas para representar a variabilidade ou incerteza associada às medições feitas em um conjunto de dados.\n\nlibrary(gsheet)\nmg &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=983033137\")\n\nmg |&gt;\n  group_by(trat) |&gt;\n  summarise(mean_comp = mean(comp)) |&gt;\n  ggplot(aes(trat,mean_comp))+\n  geom_col(fill = \"steelblue\", width =0.5)\n\n\n\ngeom_errorbar(aes(ymin = mean_comp - sd_comp,\n                  ymax = mean_comp + sd_comp),\n              width = 0.1)\n\nmapping: ymin = ~mean_comp - sd_comp, ymax = ~mean_comp + sd_comp \ngeom_errorbar: na.rm = FALSE, orientation = NA, width = 0.1\nstat_identity: na.rm = FALSE\nposition_identity \n\nmg |&gt;\n  group_by(trat) |&gt;\n  summarise(\n    mean_comp = mean(comp),\n    sd_comp = sd(comp)) |&gt;\n  ggplot(aes(x = trat, y = mean_comp)) +\n  geom_point(size = 3) +\n  ylim(5, 20) +\n  geom_errorbar(aes(ymin = mean_comp - sd_comp, ymax = mean_comp + sd_comp), width = 0.2) +\n  annotate(geom = \"text\", x = 1, y = 17.5, label = \"*\")\n\n\n\nmg |&gt;\n  ggplot(aes(trat,comp))+\n  geom_jitter(width =0.1)"
  },
  {
    "objectID": "Aula7.html",
    "href": "Aula7.html",
    "title": "Transformação dos dados",
    "section": "",
    "text": "Exemplo: fazer a raiz quadrada de todos os valores para melhorar a normalidade com a função mutate() e adicionando sqrt a count.\n\nlibrary (ggplot2)\n\ntheme_set(theme_bw())\n\ninseticida &lt;- InsectSprays\nlibrary(tidyverse)\ninseticida |&gt;\n  count(spray)\n\n  spray  n\n1     A 12\n2     B 12\n3     C 12\n4     D 12\n5     E 12\n6     F 12\n\n\n\nlibrary(dplyr)\ninseticida &lt;- inseticida |&gt;\n  mutate(count2 = sqrt(count))\n\ninseticida |&gt;\n  ggplot(aes(spray, count2))+\n  geom_boxplot()\n\n\n\n\n\nm2 &lt;- lm(count2 ~spray,\n         data = inseticida)\nsummary(m2)\n\n\nCall:\nlm(formula = count2 ~ spray, data = inseticida)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.24486 -0.39970 -0.01902  0.42661  1.40089 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   3.7607     0.1814  20.733  &lt; 2e-16 ***\nsprayB        0.1160     0.2565   0.452    0.653    \nsprayC       -2.5158     0.2565  -9.807 1.64e-14 ***\nsprayD       -1.5963     0.2565  -6.223 3.80e-08 ***\nsprayE       -1.9512     0.2565  -7.606 1.34e-10 ***\nsprayF        0.2579     0.2565   1.006    0.318    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6283 on 66 degrees of freedom\nMultiple R-squared:  0.7724,    Adjusted R-squared:  0.7552 \nF-statistic:  44.8 on 5 and 66 DF,  p-value: &lt; 2.2e-16\n\nanova(m2)\n\nAnalysis of Variance Table\n\nResponse: count2\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nspray      5 88.438 17.6876  44.799 &lt; 2.2e-16 ***\nResiduals 66 26.058  0.3948                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(emmeans)\nm2_medias &lt;- emmeans( m2, ~ spray)\nplot(m2_medias)\n\n\n\nlibrary(multcomp)\ncld(m2_medias)\n\n spray emmean    SE df lower.CL upper.CL .group\n C       1.24 0.181 66    0.883     1.61  1    \n E       1.81 0.181 66    1.447     2.17  12   \n D       2.16 0.181 66    1.802     2.53   2   \n A       3.76 0.181 66    3.399     4.12    3  \n B       3.88 0.181 66    3.514     4.24    3  \n F       4.02 0.181 66    3.656     4.38    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\npwpm(m2_medias)\n\n       A      B      C      D      E      F\nA [3.76] 0.9975 &lt;.0001 &lt;.0001 &lt;.0001 0.9145\nB -0.116 [3.88] &lt;.0001 &lt;.0001 &lt;.0001 0.9936\nC  2.516  2.632 [1.24] 0.0081 0.2513 &lt;.0001\nD  1.596  1.712 -0.919 [2.16] 0.7366 &lt;.0001\nE  1.951  2.067 -0.565  0.355 [1.81] &lt;.0001\nF -0.258 -0.142 -2.774 -1.854 -2.209 [4.02]\n\nRow and column labels: spray\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\npwpp(m2_medias)\n\n\n\npairs(m2_medias)\n\n contrast estimate    SE df t.ratio p.value\n A - B      -0.116 0.257 66  -0.452  0.9975\n A - C       2.516 0.257 66   9.807  &lt;.0001\n A - D       1.596 0.257 66   6.223  &lt;.0001\n A - E       1.951 0.257 66   7.606  &lt;.0001\n A - F      -0.258 0.257 66  -1.006  0.9145\n B - C       2.632 0.257 66  10.259  &lt;.0001\n B - D       1.712 0.257 66   6.675  &lt;.0001\n B - E       2.067 0.257 66   8.058  &lt;.0001\n B - F      -0.142 0.257 66  -0.554  0.9936\n C - D      -0.919 0.257 66  -3.584  0.0081\n C - E      -0.565 0.257 66  -2.201  0.2513\n C - F      -2.774 0.257 66 -10.813  &lt;.0001\n D - E       0.355 0.257 66   1.383  0.7366\n D - F      -1.854 0.257 66  -7.229  &lt;.0001\n E - F      -2.209 0.257 66  -8.612  &lt;.0001\n\nP value adjustment: tukey method for comparing a family of 6 estimates \n\nm2$residuals\n\n          1           2           3           4           5           6 \n-0.59840073 -1.11492708  0.71145756 -0.01902101 -0.01902101 -0.29657678 \n          7           8           9          10          11          12 \n-0.59840073  1.03515313  0.36242723  0.71145756 -0.01902101 -0.15512712 \n         13          14          15          16          17          18 \n-0.56000661  0.24647423  0.70594430 -0.56000661  0.12336860 -0.13497401 \n         19          20          21          22          23          24 \n 0.24647423  0.24647423  0.48226755  0.70594430 -1.23088009 -0.27108012 \n         25          26          27          28          29          30 \n-1.24485667 -0.24485667  1.40089464  0.16935689  0.48719414 -0.24485667 \n         31          32          33          34          35          36 \n 0.16935689 -0.24485667  0.48719414 -1.24485667 -0.24485667  0.75514333 \n         37          38          39          40          41          42 \n-0.43230306  0.07171411  1.29974775  0.28513587 -0.16435387 -0.43230306 \n         43          44          45          46          47          48 \n 0.07171411  0.07171411  0.07171411  0.07171411 -0.75014031 -0.16435387 \n         49          50          51          52          53          54 \n-0.07741021  0.42660696 -0.07741021  0.42660696 -0.07741021  0.64002872 \n         55          56          57          58          59          60 \n-0.80946102 -0.80946102 -0.07741021 -0.39524746  0.64002872  0.19053898 \n         61          62          63          64          65          66 \n-0.70199237 -1.01861716 -0.14563382  0.67179860 -0.14563382 -0.01861716 \n         67          68          69          70          71          72 \n-0.41306589 -0.85633950  1.08040235  1.08040235  0.88036232 -0.41306589 \n\nhist(m2$residuals)\n\n\n\nqqnorm(m2$residuals)\nqqline(m2$residuals)\n\n\n\nshapiro.test(m2$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m2$residuals\nW = 0.98721, p-value = 0.6814\n\nbartlett.test(count2 ~spray,\n              data = inseticida)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  count2 by spray\nBartlett's K-squared = 3.7525, df = 5, p-value = 0.5856\n\nlibrary(performance)\ncheck_normality(m2)\n\nOK: residuals appear as normally distributed (p = 0.681).\n\ncheck_heteroscedasticity(m2)\n\nOK: Error variance appears to be homoscedastic (p = 0.854).\n\nlibrary(DHARMa)\nplot(simulateResiduals(m2))\n\n\n\n#transformação Box-Cox\n\nlibrary(MASS)\nb &lt;- boxcox(lm(inseticida$count+0.1 ~1))\n\n\n\nlambda &lt;- b$x[which.max(b$y)]\nlambda &lt;- 0.5\n\ninseticida$count3 &lt;- (inseticida$count ^ lambda - 1)/ lambda\ninseticida$count3\n\n [1]  4.3245553  3.2915026  6.9442719  5.4833148  5.4833148  4.9282032\n [7]  4.3245553  7.5916630  6.2462113  6.9442719  5.4833148  5.2111026\n[13]  4.6332496  6.2462113  7.1651514  4.6332496  6.0000000  5.4833148\n[19]  6.2462113  6.2462113  6.7177979  7.1651514  3.2915026  5.2111026\n[25] -2.0000000  0.0000000  3.2915026  0.8284271  1.4641016  0.0000000\n[31]  0.8284271  0.0000000  1.4641016 -2.0000000  0.0000000  2.0000000\n[37]  1.4641016  2.4721360  4.9282032  2.8989795  2.0000000  1.4641016\n[43]  2.4721360  2.4721360  2.4721360  2.4721360  0.8284271  2.0000000\n[49]  1.4641016  2.4721360  1.4641016  2.4721360  1.4641016  2.8989795\n[55]  0.0000000  0.0000000  1.4641016  0.8284271  2.8989795  2.0000000\n[61]  4.6332496  4.0000000  5.7459667  7.3808315  5.7459667  6.0000000\n[67]  5.2111026  4.3245553  8.1980390  8.1980390  7.7979590  5.2111026\n\n\nCom os dados transformados o teste de Shapiro-wilk mostra que a distribuição pode ser considerada normal.\nOs residuaos ficaram mais próximo ao esperado.\nNo teste de Barlett o p valor deu 58%, significa que tem-se 58% de chance de encontrar o valor determinado. Como o valor é maior que 0,05 as variâncias são consideradas homogêneas.\nteste darma mostra se os tratamentos estão dentro da variância esperada e os agrupamentos estão de acordo com a saída da anova.\nDe acordo com a anova pelo menos uma média difere das demais.\nUtilizando o pacote MASS - lambda valor de x em q y é o valor máximo (lambda 0.5 é igual a raiz quadrada)."
  },
  {
    "objectID": "Aula7.html#alternativa-1---transformação",
    "href": "Aula7.html#alternativa-1---transformação",
    "title": "Transformação dos dados",
    "section": "",
    "text": "Exemplo: fazer a raiz quadrada de todos os valores para melhorar a normalidade com a função mutate() e adicionando sqrt a count.\n\nlibrary (ggplot2)\n\ntheme_set(theme_bw())\n\ninseticida &lt;- InsectSprays\nlibrary(tidyverse)\ninseticida |&gt;\n  count(spray)\n\n  spray  n\n1     A 12\n2     B 12\n3     C 12\n4     D 12\n5     E 12\n6     F 12\n\n\n\nlibrary(dplyr)\ninseticida &lt;- inseticida |&gt;\n  mutate(count2 = sqrt(count))\n\ninseticida |&gt;\n  ggplot(aes(spray, count2))+\n  geom_boxplot()\n\n\n\n\n\nm2 &lt;- lm(count2 ~spray,\n         data = inseticida)\nsummary(m2)\n\n\nCall:\nlm(formula = count2 ~ spray, data = inseticida)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.24486 -0.39970 -0.01902  0.42661  1.40089 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   3.7607     0.1814  20.733  &lt; 2e-16 ***\nsprayB        0.1160     0.2565   0.452    0.653    \nsprayC       -2.5158     0.2565  -9.807 1.64e-14 ***\nsprayD       -1.5963     0.2565  -6.223 3.80e-08 ***\nsprayE       -1.9512     0.2565  -7.606 1.34e-10 ***\nsprayF        0.2579     0.2565   1.006    0.318    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6283 on 66 degrees of freedom\nMultiple R-squared:  0.7724,    Adjusted R-squared:  0.7552 \nF-statistic:  44.8 on 5 and 66 DF,  p-value: &lt; 2.2e-16\n\nanova(m2)\n\nAnalysis of Variance Table\n\nResponse: count2\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nspray      5 88.438 17.6876  44.799 &lt; 2.2e-16 ***\nResiduals 66 26.058  0.3948                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(emmeans)\nm2_medias &lt;- emmeans( m2, ~ spray)\nplot(m2_medias)\n\n\n\nlibrary(multcomp)\ncld(m2_medias)\n\n spray emmean    SE df lower.CL upper.CL .group\n C       1.24 0.181 66    0.883     1.61  1    \n E       1.81 0.181 66    1.447     2.17  12   \n D       2.16 0.181 66    1.802     2.53   2   \n A       3.76 0.181 66    3.399     4.12    3  \n B       3.88 0.181 66    3.514     4.24    3  \n F       4.02 0.181 66    3.656     4.38    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\npwpm(m2_medias)\n\n       A      B      C      D      E      F\nA [3.76] 0.9975 &lt;.0001 &lt;.0001 &lt;.0001 0.9145\nB -0.116 [3.88] &lt;.0001 &lt;.0001 &lt;.0001 0.9936\nC  2.516  2.632 [1.24] 0.0081 0.2513 &lt;.0001\nD  1.596  1.712 -0.919 [2.16] 0.7366 &lt;.0001\nE  1.951  2.067 -0.565  0.355 [1.81] &lt;.0001\nF -0.258 -0.142 -2.774 -1.854 -2.209 [4.02]\n\nRow and column labels: spray\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\npwpp(m2_medias)\n\n\n\npairs(m2_medias)\n\n contrast estimate    SE df t.ratio p.value\n A - B      -0.116 0.257 66  -0.452  0.9975\n A - C       2.516 0.257 66   9.807  &lt;.0001\n A - D       1.596 0.257 66   6.223  &lt;.0001\n A - E       1.951 0.257 66   7.606  &lt;.0001\n A - F      -0.258 0.257 66  -1.006  0.9145\n B - C       2.632 0.257 66  10.259  &lt;.0001\n B - D       1.712 0.257 66   6.675  &lt;.0001\n B - E       2.067 0.257 66   8.058  &lt;.0001\n B - F      -0.142 0.257 66  -0.554  0.9936\n C - D      -0.919 0.257 66  -3.584  0.0081\n C - E      -0.565 0.257 66  -2.201  0.2513\n C - F      -2.774 0.257 66 -10.813  &lt;.0001\n D - E       0.355 0.257 66   1.383  0.7366\n D - F      -1.854 0.257 66  -7.229  &lt;.0001\n E - F      -2.209 0.257 66  -8.612  &lt;.0001\n\nP value adjustment: tukey method for comparing a family of 6 estimates \n\nm2$residuals\n\n          1           2           3           4           5           6 \n-0.59840073 -1.11492708  0.71145756 -0.01902101 -0.01902101 -0.29657678 \n          7           8           9          10          11          12 \n-0.59840073  1.03515313  0.36242723  0.71145756 -0.01902101 -0.15512712 \n         13          14          15          16          17          18 \n-0.56000661  0.24647423  0.70594430 -0.56000661  0.12336860 -0.13497401 \n         19          20          21          22          23          24 \n 0.24647423  0.24647423  0.48226755  0.70594430 -1.23088009 -0.27108012 \n         25          26          27          28          29          30 \n-1.24485667 -0.24485667  1.40089464  0.16935689  0.48719414 -0.24485667 \n         31          32          33          34          35          36 \n 0.16935689 -0.24485667  0.48719414 -1.24485667 -0.24485667  0.75514333 \n         37          38          39          40          41          42 \n-0.43230306  0.07171411  1.29974775  0.28513587 -0.16435387 -0.43230306 \n         43          44          45          46          47          48 \n 0.07171411  0.07171411  0.07171411  0.07171411 -0.75014031 -0.16435387 \n         49          50          51          52          53          54 \n-0.07741021  0.42660696 -0.07741021  0.42660696 -0.07741021  0.64002872 \n         55          56          57          58          59          60 \n-0.80946102 -0.80946102 -0.07741021 -0.39524746  0.64002872  0.19053898 \n         61          62          63          64          65          66 \n-0.70199237 -1.01861716 -0.14563382  0.67179860 -0.14563382 -0.01861716 \n         67          68          69          70          71          72 \n-0.41306589 -0.85633950  1.08040235  1.08040235  0.88036232 -0.41306589 \n\nhist(m2$residuals)\n\n\n\nqqnorm(m2$residuals)\nqqline(m2$residuals)\n\n\n\nshapiro.test(m2$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m2$residuals\nW = 0.98721, p-value = 0.6814\n\nbartlett.test(count2 ~spray,\n              data = inseticida)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  count2 by spray\nBartlett's K-squared = 3.7525, df = 5, p-value = 0.5856\n\nlibrary(performance)\ncheck_normality(m2)\n\nOK: residuals appear as normally distributed (p = 0.681).\n\ncheck_heteroscedasticity(m2)\n\nOK: Error variance appears to be homoscedastic (p = 0.854).\n\nlibrary(DHARMa)\nplot(simulateResiduals(m2))\n\n\n\n#transformação Box-Cox\n\nlibrary(MASS)\nb &lt;- boxcox(lm(inseticida$count+0.1 ~1))\n\n\n\nlambda &lt;- b$x[which.max(b$y)]\nlambda &lt;- 0.5\n\ninseticida$count3 &lt;- (inseticida$count ^ lambda - 1)/ lambda\ninseticida$count3\n\n [1]  4.3245553  3.2915026  6.9442719  5.4833148  5.4833148  4.9282032\n [7]  4.3245553  7.5916630  6.2462113  6.9442719  5.4833148  5.2111026\n[13]  4.6332496  6.2462113  7.1651514  4.6332496  6.0000000  5.4833148\n[19]  6.2462113  6.2462113  6.7177979  7.1651514  3.2915026  5.2111026\n[25] -2.0000000  0.0000000  3.2915026  0.8284271  1.4641016  0.0000000\n[31]  0.8284271  0.0000000  1.4641016 -2.0000000  0.0000000  2.0000000\n[37]  1.4641016  2.4721360  4.9282032  2.8989795  2.0000000  1.4641016\n[43]  2.4721360  2.4721360  2.4721360  2.4721360  0.8284271  2.0000000\n[49]  1.4641016  2.4721360  1.4641016  2.4721360  1.4641016  2.8989795\n[55]  0.0000000  0.0000000  1.4641016  0.8284271  2.8989795  2.0000000\n[61]  4.6332496  4.0000000  5.7459667  7.3808315  5.7459667  6.0000000\n[67]  5.2111026  4.3245553  8.1980390  8.1980390  7.7979590  5.2111026\n\n\nCom os dados transformados o teste de Shapiro-wilk mostra que a distribuição pode ser considerada normal.\nOs residuaos ficaram mais próximo ao esperado.\nNo teste de Barlett o p valor deu 58%, significa que tem-se 58% de chance de encontrar o valor determinado. Como o valor é maior que 0,05 as variâncias são consideradas homogêneas.\nteste darma mostra se os tratamentos estão dentro da variância esperada e os agrupamentos estão de acordo com a saída da anova.\nDe acordo com a anova pelo menos uma média difere das demais.\nUtilizando o pacote MASS - lambda valor de x em q y é o valor máximo (lambda 0.5 é igual a raiz quadrada)."
  },
  {
    "objectID": "Aula7.html#alternativa-2-teste-não-paramétrico",
    "href": "Aula7.html#alternativa-2-teste-não-paramétrico",
    "title": "Transformação dos dados",
    "section": "Alternativa 2 teste não paramétrico",
    "text": "Alternativa 2 teste não paramétrico\nNesta alternativa pode-se trabalhar com a saida original sem transformação. Usa-se a função kruskal() quando são 3 grupos ou mais.\n\nlibrary(agricolae)\nkruskal.test(count~spray,\n             data = inseticida)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  count by spray\nKruskal-Wallis chi-squared = 54.691, df = 5, p-value = 1.511e-10\n\nm3 &lt;- kruskal(inseticida$count,\n        inseticida$spray,\n        group = TRUE)\nm3\n\n$statistics\n     Chisq Df      p.chisq  t.value      MSD\n  54.69134  5 1.510845e-10 1.996564 8.462804\n\n$parameters\n            test p.ajusted           name.t ntr alpha\n  Kruskal-Wallis      none inseticida$spray   6  0.05\n\n$means\n  inseticida.count     rank      std  r Min Max   Q25  Q50   Q75\nA        14.500000 52.16667 4.719399 12   7  23 11.50 14.0 17.75\nB        15.333333 54.83333 4.271115 12   7  21 12.50 16.5 17.50\nC         2.083333 11.45833 1.975225 12   0   7  1.00  1.5  3.00\nD         4.916667 25.58333 2.503028 12   2  12  3.75  5.0  5.00\nE         3.500000 19.33333 1.732051 12   1   6  2.75  3.0  5.00\nF        16.666667 55.62500 6.213378 12   9  26 12.50 15.0 22.50\n\n$comparison\nNULL\n\n$groups\n  inseticida$count groups\nF         55.62500      a\nB         54.83333      a\nA         52.16667      a\nD         25.58333      b\nE         19.33333     bc\nC         11.45833      c\n\nattr(,\"class\")\n[1] \"group\"\n\n\nNa hipótese nula - Ho: médias iguais, H1: rejeita a hipotese nula que as medias são iguais.\nPelo agrupamento m3, apresenta o resultado do teste de fisher (as letrinhas), cálculo da média dos tratamentose e o ranking de ordenamento do menor para o maior. Pode-se ver nos resultados, 3 grupos - a, b e c. Resultados que batem com o boxplot gerado anteriormente.\npode-se observar que o modelo não-paramétrico apresentou o resultado igual ao paramétrico transformado."
  },
  {
    "objectID": "Aula7.html#alternativa-3---glms",
    "href": "Aula7.html#alternativa-3---glms",
    "title": "Transformação dos dados",
    "section": "Alternativa 3 - GLMs",
    "text": "Alternativa 3 - GLMs\nO modelo 4 não assume a distribuição normal. Portanto, usa-se um modelo diferente: modelo linear generalizado.\n\nm4 &lt;- glm(count ~spray,\n          family = poisson,\n          data = inseticida)\nm4\n\n\nCall:  glm(formula = count ~ spray, family = poisson, data = inseticida)\n\nCoefficients:\n(Intercept)       sprayB       sprayC       sprayD       sprayE       sprayF  \n    2.67415      0.05588     -1.94018     -1.08152     -1.42139      0.13926  \n\nDegrees of Freedom: 71 Total (i.e. Null);  66 Residual\nNull Deviance:      409 \nResidual Deviance: 98.33    AIC: 376.6\n\nsummary(m4)\n\n\nCall:\nglm(formula = count ~ spray, family = poisson, data = inseticida)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  2.67415    0.07581  35.274  &lt; 2e-16 ***\nsprayB       0.05588    0.10574   0.528    0.597    \nsprayC      -1.94018    0.21389  -9.071  &lt; 2e-16 ***\nsprayD      -1.08152    0.15065  -7.179 7.03e-13 ***\nsprayE      -1.42139    0.17192  -8.268  &lt; 2e-16 ***\nsprayF       0.13926    0.10367   1.343    0.179    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 409.041  on 71  degrees of freedom\nResidual deviance:  98.329  on 66  degrees of freedom\nAIC: 376.59\n\nNumber of Fisher Scoring iterations: 5\n\nanova(m4)\n\nAnalysis of Deviance Table\n\nModel: poisson, link: log\n\nResponse: count\n\nTerms added sequentially (first to last)\n\n      Df Deviance Resid. Df Resid. Dev\nNULL                     71     409.04\nspray  5   310.71        66      98.33\n\nlibrary(car)\nAnova(m4)\n\nAnalysis of Deviance Table (Type II tests)\n\nResponse: count\n      LR Chisq Df Pr(&gt;Chisq)    \nspray   310.71  5  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nplot(simulateResiduals(m4))\n\n\n\nm4_medias &lt;- emmeans(m4, ~spray,\n                     type = \"response\")\nm4_medias\n\n spray  rate    SE  df asymp.LCL asymp.UCL\n A     14.50 1.099 Inf     12.50     16.82\n B     15.33 1.130 Inf     13.27     17.72\n C      2.08 0.417 Inf      1.41      3.08\n D      4.92 0.640 Inf      3.81      6.35\n E      3.50 0.540 Inf      2.59      4.74\n F     16.67 1.179 Inf     14.51     19.14\n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log scale \n\ncld(m4_medias)\n\n spray  rate    SE  df asymp.LCL asymp.UCL .group\n C      2.08 0.417 Inf      1.41      3.08  1    \n E      3.50 0.540 Inf      2.59      4.74  12   \n D      4.92 0.640 Inf      3.81      6.35   2   \n A     14.50 1.099 Inf     12.50     16.82    3  \n B     15.33 1.130 Inf     13.27     17.72    3  \n F     16.67 1.179 Inf     14.51     19.14    3  \n\nConfidence level used: 0.95 \nIntervals are back-transformed from the log scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nTests are performed on the log scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nIsso ajusta um modelo de regressão Poisson onde a variável dependente é count e a variável independente é spray, usando os dados contidos no dataframe inseticida.\nA função anova() realiza uma análise de variância do modelo, que é útil para determinar a significância global do modelo de regressão Poisson.\nComo resultados, observa-se diferença estatística e as variâncias são homogêneas (diferente do original).\nFunção emmeans() - calcula o log, response=dados originais (14, 50, 95% das vezes dentro do intervalo)."
  },
  {
    "objectID": "Aula8.html",
    "href": "Aula8.html",
    "title": "Anova fatorial",
    "section": "",
    "text": "A Anova fatorial é uma extensão da análise de variância que permite investigar o efeito de dois ou mais fatores categóricos e suas interações em uma variável dependente contínua.\nlibrary(gsheet)\n\nli &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=2023059672\")\nlibrary(ggplot2)\nli |&gt;\n  ggplot(aes(factor(dose), severity, color = factor(dose)))+\n  geom_jitter(width = 0.1)+\n  facet_wrap(~treat)"
  },
  {
    "objectID": "Aula8.html#modelo-fatorialtwo-way-anova",
    "href": "Aula8.html#modelo-fatorialtwo-way-anova",
    "title": "Anova fatorial",
    "section": "Modelo fatorial(two-way anova)",
    "text": "Modelo fatorial(two-way anova)\nFatorial testa a interação entre os tratamentos.\n\nmf &lt;- lm(severity ~treat*factor(dose),\n         data = li)\nmf\n\n\nCall:\nlm(formula = severity ~ treat * factor(dose), data = li)\n\nCoefficients:\n                    (Intercept)                treatTebuconazole  \n                         0.2921                          -0.2711  \n                  factor(dose)2  treatTebuconazole:factor(dose)2  \n                        -0.2420                           0.2412  \n\nanova(mf)\n\nAnalysis of Variance Table\n\nResponse: severity\n                   Df   Sum Sq  Mean Sq F value    Pr(&gt;F)    \ntreat               1 0.113232 0.113232  30.358 4.754e-05 ***\nfactor(dose)        1 0.073683 0.073683  19.755 0.0004077 ***\ntreat:factor(dose)  1 0.072739 0.072739  19.502 0.0004326 ***\nResiduals          16 0.059678 0.003730                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(DHARMa)\nplot(simulateResiduals(mf))\n\n\n\nlibrary(emmeans)\nmf_medias &lt;- emmeans(mf, ~ dose | treat)\nmf_medias\n\ntreat = Ionic liquid:\n dose emmean     SE df lower.CL upper.CL\n  0.5 0.2921 0.0273 16  0.23420   0.3500\n  2.0 0.0501 0.0273 16 -0.00781   0.1080\n\ntreat = Tebuconazole:\n dose emmean     SE df lower.CL upper.CL\n  0.5 0.0210 0.0273 16 -0.03690   0.0789\n  2.0 0.0202 0.0273 16 -0.03768   0.0781\n\nConfidence level used: 0.95 \n\nlibrary(multcomp)\ncld(mf_medias)\n\ntreat = Ionic liquid:\n dose emmean     SE df lower.CL upper.CL .group\n  2.0 0.0501 0.0273 16 -0.00781   0.1080  1    \n  0.5 0.2921 0.0273 16  0.23420   0.3500   2   \n\ntreat = Tebuconazole:\n dose emmean     SE df lower.CL upper.CL .group\n  2.0 0.0202 0.0273 16 -0.03768   0.0781  1    \n  0.5 0.0210 0.0273 16 -0.03690   0.0789  1    \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\nshapiro.test(mf$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  mf$residuals\nW = 0.86792, p-value = 0.0108\n\n\nO exemplo mostra se é significativo o efeito da dose no tratamento (estimar as médias de um dentro do outro)."
  },
  {
    "objectID": "Aula14.html",
    "href": "Aula14.html",
    "title": "Mapas",
    "section": "",
    "text": "Os pacotes rnaturalearth e rnaturalearthhires podem ser usados para construção de mapas no R.\nlibrary(rnaturalearth)\nlibrary(remotes)\n\n##remotes::install_github(\"ropensci/rnaturalearthhires\")\n##install.packages(\"rnaturalearthhires\", repos = \"https://ropensc\")\n\nlibrary(rnaturalearthhires)\nlibrary(ggplot2)"
  },
  {
    "objectID": "Aula14.html#mapa-do-brasil",
    "href": "Aula14.html#mapa-do-brasil",
    "title": "Mapas",
    "section": "Mapa do Brasil",
    "text": "Mapa do Brasil\n\nBRA &lt;- ne_states(country = \"Brazil\",\n                 returnclass = \"sf\")\n\nworld &lt;- ne_countries()\n\n#library(tidyverse)\nggplot(BRA) +\n  geom_sf(fill = \"white\")\n\n\n\nggplot(BRA) +\n  geom_sf(fill = \"black\",\n          color = \"yellow\",\n          linewidth =1)"
  },
  {
    "objectID": "Aula14.html#mapa-do-peru",
    "href": "Aula14.html#mapa-do-peru",
    "title": "Mapas",
    "section": "Mapa do Peru",
    "text": "Mapa do Peru\n\nBRA &lt;- ne_states(country = \"Peru\",\n                 returnclass = \"sf\")\n\nworld &lt;- ne_countries()\n\n#library(tidyverse)\nggplot(BRA) +\n  geom_sf(fill = \"white\")"
  },
  {
    "objectID": "Aula14.html#mapa-da-colômbia",
    "href": "Aula14.html#mapa-da-colômbia",
    "title": "Mapas",
    "section": "Mapa da Colômbia",
    "text": "Mapa da Colômbia\n\nBRA &lt;- ne_states(country = \"Colombia\",\n                 returnclass = \"sf\")\n\nworld &lt;- ne_countries()\n\n#library(tidyverse)\nggplot(BRA) +\n  geom_sf(fill = \"white\")"
  },
  {
    "objectID": "Aula14.html#mapa-com-marcações",
    "href": "Aula14.html#mapa-com-marcações",
    "title": "Mapas",
    "section": "Mapa com marcações",
    "text": "Mapa com marcações\n\nlibrary(r4pde)\n\nsbr &lt;- RustSoybean\n\n\nsbr |&gt; \n  ggplot(aes(longitude, latitude)) +\n  geom_point() +\n  coord_sf()\n\n\n\n# juntar a camada de ponto e sobrepor o mapa\n\n\nlibrary(ggthemes)\n\nBRA &lt;- ne_states(country = \"Brazil\",\n                 returnclass = \"sf\")\n\nworld &lt;- ne_countries()\n\n#library(tidyverse)\nggplot(BRA) +\n  geom_sf(fill = \"white\")\n\n\n\nggplot(BRA) +\n  geom_sf(fill = \"black\",\n          color = \"yellow\",\n          linewidth =1) +\n  geom_point(data = sbr, aes(longitude, latitude),\n             color = \"white\") +\n  theme_map()"
  },
  {
    "objectID": "Aula14.html#mapa-interativo",
    "href": "Aula14.html#mapa-interativo",
    "title": "Mapas",
    "section": "Mapa interativo",
    "text": "Mapa interativo\n\nbra &lt;-ggplot(BRA) +\n  geom_sf(fill = \"black\",\n          color = \"white\",\n          linewidth = 0.3) +\n geom_sf(data = MG, fill = \"black\") +\n  geom_point(data = sbr, aes(longitude, latitude),\n             color = \"white\") +\n  theme_map() +\n  annotation_north_arrow(which_north = \"grid\")\n\nlibrary(plotly)\nggplotly(bra)"
  },
  {
    "objectID": "Aula14.html#mapa-com-gráficos",
    "href": "Aula14.html#mapa-com-gráficos",
    "title": "Mapas",
    "section": "Mapa com gráficos",
    "text": "Mapa com gráficos\n\nlibrary(ggplot2)\nlibrary(gsheet)\nlibrary(scatterpie)\nlibrary(ggrepel)\n\nmapa &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1pAIFKsdKxk_UQQXdYwIO-O5NOkYNhpclImJcLziYnk4/edit?usp=sharing\")\n\nggplot(BRA) +\n  geom_sf(fill = \"gray70\", alpha = 0.5, color = \"white\") +\n  coord_sf()+\n  geom_scatterpie(aes(x = lon, y = lat, r = 0.6), alpha = 0.8, color = NA, data = mapa,\n                  cols = c(\"DFC\",\n                           \"MA\",\n                           \"FER\",\n                           \"ANTR\",\n                           \"OIDIO\"))+\n  geom_text_repel(data = mapa, aes(lon, lat, label = Local),\n                   size = 2, nudge_x = 0.2, nudge_y = 0.27, color = \"gray30\", family = \"Arial\") +\n  ggthemes::scale_fill_calc()+\n  ggthemes::theme_map() +\n  labs(x = \"Longitude\", y = \"Latitude\", legend = \"\", fill = \"Doença\")+\n  theme(legend.position = \"bottom\", text = element_text(family = \"Arial\", size = 8))"
  },
  {
    "objectID": "Aula9.html",
    "href": "Aula9.html",
    "title": "Anova com DBC",
    "section": "",
    "text": "Delineamento experimental que contém o terceiro príncipio da experimentação, que é o controle local. Este delineamento reduz as fontes de variação, com isso o erro experimental também é reduzido (não favorece um tratamento em detrimento de outro)."
  },
  {
    "objectID": "Aula9.html#anova-com-blocos-casualizados",
    "href": "Aula9.html#anova-com-blocos-casualizados",
    "title": "Anova com DBC",
    "section": "",
    "text": "Delineamento experimental que contém o terceiro príncipio da experimentação, que é o controle local. Este delineamento reduz as fontes de variação, com isso o erro experimental também é reduzido (não favorece um tratamento em detrimento de outro)."
  },
  {
    "objectID": "Aula9.html#importar-os-dados",
    "href": "Aula9.html#importar-os-dados",
    "title": "Anova com DBC",
    "section": "Importar os dados",
    "text": "Importar os dados\n\nlibrary(tidyverse)\nlibrary(gsheet)\n\nsoja &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=866852711\")\n\nsoja &lt;- soja |&gt;\n  mutate(TRAT = as.factor(TRAT),\n         BLOCO = as.factor(BLOCO))"
  },
  {
    "objectID": "Aula9.html#visualizar-os-dados",
    "href": "Aula9.html#visualizar-os-dados",
    "title": "Anova com DBC",
    "section": "Visualizar os dados",
    "text": "Visualizar os dados\n\ndfc&lt;- soja |&gt;\n  ggplot(aes(TRAT, DFC))+\n  geom_jitter(width= 0.05, color=\n                \"gray70\")+\n  stat_summary(fun.data = \n                 \"mean_cl_boot\", size=0.5, color=\n                 \"black\", alpha= 0.05)\ndfc\n\n\n\nfer &lt;- soja |&gt;\n  ggplot(aes(TRAT, FER))+\n  geom_jitter(width= 0.05, color=\n                \"gray70\")+\n  stat_summary(fun.data = \n                 \"mean_cl_boot\", size=0.5, color=\n                 \"black\", alpha= 0.05)\nfer\n\n\n\nprod &lt;- soja |&gt;\n  ggplot(aes(TRAT, PROD))+\n  geom_jitter(width= 0.05, color=\n                \"gray70\")+\n  stat_summary(fun.data = \n                 \"mean_cl_boot\", size=0.5, color=\n                 \"black\", alpha= 0.05)\nprod\n\n\n\nlibrary(ggpubr)\nggarrange(dfc,fer,prod, ncol=3,nrow=1)"
  },
  {
    "objectID": "Aula9.html#anova-para-a-variável-dfc",
    "href": "Aula9.html#anova-para-a-variável-dfc",
    "title": "Anova com DBC",
    "section": "Anova para a variável DFC",
    "text": "Anova para a variável DFC\n\naov_dfc &lt;- lm(DFC ~ TRAT + BLOCO,\n              data = soja)\nanova(aov_dfc)\n\nAnalysis of Variance Table\n\nResponse: DFC\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nTRAT       7 149.299 21.3284 51.5490 8.218e-12 ***\nBLOCO      3   0.461  0.1537  0.3716    0.7743    \nResiduals 21   8.689  0.4138                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(performance)\ncheck_heteroscedasticity(aov_dfc)\n\nOK: Error variance appears to be homoscedastic (p = 0.532).\n\ncheck_normality(aov_dfc)\n\nOK: residuals appear as normally distributed (p = 0.978).\n\nlibrary(emmeans)\nmedias_dfc &lt;- emmeans(aov_dfc, ~TRAT)\nmedias_dfc\n\n TRAT emmean    SE df lower.CL upper.CL\n 1     10.88 0.322 21    10.21    11.54\n 2      6.42 0.322 21     5.76     7.09\n 3      6.05 0.322 21     5.38     6.72\n 4      4.75 0.322 21     4.08     5.42\n 5      4.20 0.322 21     3.53     4.87\n 6      4.00 0.322 21     3.33     4.67\n 7      4.08 0.322 21     3.41     4.74\n 8      4.58 0.322 21     3.91     5.24\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\npwpm(medias_dfc)\n\n        1       2       3       4       5       6       7       8\n1 [10.87]  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001\n2   4.450 [ 6.42]  0.9896  0.0249  0.0017  0.0006  0.0009  0.0107\n3   4.825   0.375 [ 6.05]  0.1329  0.0107  0.0040  0.0058  0.0628\n4   6.125   1.675   1.300 [ 4.75]  0.9202  0.7173  0.8072  0.9999\n5   6.675   2.225   1.850   0.550 [ 4.20]  0.9998  1.0000  0.9896\n6   6.875   2.425   2.050   0.750   0.200 [ 4.00]  1.0000  0.9020\n7   6.800   2.350   1.975   0.675   0.125  -0.075 [ 4.07]  0.9499\n8   6.300   1.850   1.475   0.175  -0.375  -0.575  -0.500 [ 4.57]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\nlibrary(writexl)\nlibrary(multcomp)\ncld2 &lt;- cld(medias_dfc, Letters = LETTERS)\nwrite_xlsx (cld2, \"df.xlsx\" )"
  },
  {
    "objectID": "Aula9.html#anova-para-a-variável-fer",
    "href": "Aula9.html#anova-para-a-variável-fer",
    "title": "Anova com DBC",
    "section": "Anova para a variável FER",
    "text": "Anova para a variável FER\n\naov_fer &lt;- lm(FER2 &lt;- log(FER) ~ TRAT + BLOCO,\n              data = soja)\nanova(aov_fer)\n\nAnalysis of Variance Table\n\nResponse: log(FER)\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nTRAT       7 11.5210 1.64585 42.9665 4.838e-11 ***\nBLOCO      3  0.2064 0.06880  1.7961    0.1788    \nResiduals 21  0.8044 0.03831                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(performance)\ncheck_heteroscedasticity(aov_fer)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p = 0.035).\n\ncheck_normality(aov_fer)\n\nOK: residuals appear as normally distributed (p = 0.255).\n\nlibrary(emmeans)\nmedias_fer &lt;- emmeans(aov_fer, ~TRAT, type = \"response\")\nmedias_fer\n\n TRAT response    SE df lower.CL upper.CL\n 1       20.02 1.959 21    16.33    24.54\n 2        5.68 0.556 21     4.63     6.96\n 3        3.81 0.373 21     3.11     4.67\n 4        3.08 0.301 21     2.51     3.78\n 5        3.24 0.317 21     2.64     3.97\n 6        2.98 0.292 21     2.43     3.65\n 7        3.37 0.330 21     2.75     4.13\n 8        3.48 0.341 21     2.84     4.27\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nIntervals are back-transformed from the log scale \n\npwpm(medias_fer)\n\n        1       2       3       4       5       6       7       8\n1 [20.02]  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001  &lt;.0001\n2   3.525 [ 5.68]  0.1252  0.0048  0.0110  0.0028  0.0204  0.0343\n3   5.259   1.492 [ 3.81]  0.7832  0.9335  0.6440  0.9843  0.9976\n4   6.500   1.844   1.236 [ 3.08]  0.9999  1.0000  0.9976  0.9842\n5   6.178   1.753   1.175   0.951 [ 3.24]  0.9984  1.0000  0.9994\n6   6.721   1.906   1.278   1.034   1.088 [ 2.98]  0.9842  0.9431\n7   5.945   1.686   1.130   0.915   0.962   0.885 [ 3.37]  1.0000\n8   5.750   1.631   1.093   0.885   0.931   0.856   0.967 [ 3.48]\n\nRow and column labels: TRAT\nUpper triangle: P values   null = 1  adjust = \"tukey\"\nDiagonal: [Estimates] (response)   type = \"response\"\nLower triangle: Comparisons (ratio)   earlier vs. later\n\nlibrary(multcomp)\ncld(medias_fer, Letters = LETTERS)\n\n TRAT response    SE df lower.CL upper.CL .group\n 6        2.98 0.292 21     2.43     3.65  A    \n 4        3.08 0.301 21     2.51     3.78  A    \n 5        3.24 0.317 21     2.64     3.97  A    \n 7        3.37 0.330 21     2.75     4.13  A    \n 8        3.48 0.341 21     2.84     4.27  A    \n 3        3.81 0.373 21     3.11     4.67  AB   \n 2        5.68 0.556 21     4.63     6.96   B   \n 1       20.02 1.959 21    16.33    24.54    C  \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nIntervals are back-transformed from the log scale \nP value adjustment: tukey method for comparing a family of 8 estimates \nTests are performed on the log scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\nb &lt;- boxcox(lm(soja$FER ~1))\n\n\n\nlambda &lt;- b$x[which.max(b$y)]\nlambda\n\n[1] -1.555556\n\nsoja$FER2 &lt;- (soja$FER ^lambda - 1) / lambda"
  },
  {
    "objectID": "Aula9.html#anova-para-a-variável-prod",
    "href": "Aula9.html#anova-para-a-variável-prod",
    "title": "Anova com DBC",
    "section": "Anova para a variável PROD",
    "text": "Anova para a variável PROD\n\naov_prod &lt;- lm(PROD ~ TRAT + BLOCO,\n              data = soja)\n\nlibrary(agricolae)\ncv.model(aov_prod)\n\n[1] 8.057402\n\nanova(aov_prod)\n\nAnalysis of Variance Table\n\nResponse: PROD\n          Df  Sum Sq Mean Sq F value  Pr(&gt;F)  \nTRAT       7 2993906  427701  2.6367 0.04021 *\nBLOCO      3  105665   35222  0.2171 0.88340  \nResiduals 21 3406431  162211                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(performance)\ncheck_heteroscedasticity(aov_prod)\n\nOK: Error variance appears to be homoscedastic (p = 0.215).\n\ncheck_normality(aov_prod)\n\nOK: residuals appear as normally distributed (p = 0.542).\n\nlibrary(emmeans)\nmedias_prod &lt;- emmeans(aov_prod, ~TRAT)\nmedias_prod\n\n TRAT emmean  SE df lower.CL upper.CL\n 1      4219 201 21     3800     4638\n 2      4935 201 21     4516     5354\n 3      5110 201 21     4691     5529\n 4      5140 201 21     4721     5559\n 5      5122 201 21     4703     5541\n 6      5256 201 21     4837     5675\n 7      5128 201 21     4709     5546\n 8      5078 201 21     4659     5497\n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \n\npwpm(medias_prod)\n\n        1       2       3       4       5       6       7      8\n1  [4219]  0.2430  0.0792  0.0640  0.0728  0.0272  0.0700 0.0985\n2  -715.8  [4935]  0.9983  0.9953  0.9974  0.9430  0.9968 0.9995\n3  -890.8  -175.0  [5110]  1.0000  1.0000  0.9994  1.0000 1.0000\n4  -921.0  -205.3   -30.3  [5140]  1.0000  0.9999  1.0000 1.0000\n5  -902.8  -187.0   -12.0    18.3  [5122]  0.9997  1.0000 1.0000\n6 -1037.0  -321.3  -146.3  -116.0  -134.3  [5256]  0.9998 0.9981\n7  -908.3  -192.5   -17.5    12.8    -5.5   128.8  [5127] 1.0000\n8  -859.0  -143.3    31.7    62.0    43.7   178.0    49.2 [5078]\n\nRow and column labels: TRAT\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\nlibrary(multcomp)\nmedias_prod_grupo &lt;- cld(medias_prod, Letters = LETTERS)\nmedias_prod_grupo\n\n TRAT emmean  SE df lower.CL upper.CL .group\n 1      4219 201 21     3800     4638  A    \n 2      4935 201 21     4516     5354  AB   \n 8      5078 201 21     4659     5497  AB   \n 3      5110 201 21     4691     5529  AB   \n 5      5122 201 21     4703     5541  AB   \n 7      5128 201 21     4709     5546  AB   \n 4      5140 201 21     4721     5559  AB   \n 6      5256 201 21     4837     5675   B   \n\nResults are averaged over the levels of: BLOCO \nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 8 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "Aula9.html#visualização-das-médias-e-barra-de-erro.",
    "href": "Aula9.html#visualização-das-médias-e-barra-de-erro.",
    "title": "Anova com DBC",
    "section": "Visualização das médias e barra de erro.",
    "text": "Visualização das médias e barra de erro.\nO pacote writexl e função write_xlsx() permitem exportar data frames para o formato Excel, permitindo que os dados sejam facilmente compartilhados e analisados em outras plataformas.\n\ndf_prod &lt;- data.frame(medias_prod_grupo)\ndf_prod |&gt;\n  ggplot(aes(TRAT, emmean))+\n  geom_point()+\n  ylim(3000,6500)+\n  geom_errorbar(aes(min = lower.CL,\n                    max = upper.CL),\n                width = 0.1)+\nannotate(geom = \"text\", x = 1.2, y = 4200,\n         label = \"A\")\n\n\n\nknitr::kable(df_prod |&gt; dplyr::select(TRAT, emmean, .group))\n\n\n\n\n\nTRAT\nemmean\n.group\n\n\n\n\n1\n1\n4219.25\nA\n\n\n2\n2\n4935.00\nAB\n\n\n8\n8\n5078.25\nAB\n\n\n3\n3\n5110.00\nAB\n\n\n5\n5\n5122.00\nAB\n\n\n7\n7\n5127.50\nAB\n\n\n4\n4\n5140.25\nAB\n\n\n6\n6\n5256.25\nB\n\n\n\n\nlibrary(writexl)\nwrite_xlsx(df_prod, \"df.xlsx\")"
  },
  {
    "objectID": "Aula9.html#dados-de-severidade",
    "href": "Aula9.html#dados-de-severidade",
    "title": "Anova com DBC",
    "section": "Dados de severidade",
    "text": "Dados de severidade\n\ncurve &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1807247585\")\n\n\ncurve |&gt; \n  group_by(day, Irrigation) |&gt; \n  summarise(mean_sev = mean(severity)) |&gt; \n  ggplot(aes(day, mean_sev)) +\n   geom_point(which = 0.05)+ \n  geom_line()+\n  facet_wrap(~~Irrigation)"
  },
  {
    "objectID": "Aula9.html#cálculo-da-área-abaixo-da-curva-de-progressoo-da-doença-aacpd",
    "href": "Aula9.html#cálculo-da-área-abaixo-da-curva-de-progressoo-da-doença-aacpd",
    "title": "Anova com DBC",
    "section": "Cálculo da Área Abaixo da Curva de progressoo da Doença (AACPD)",
    "text": "Cálculo da Área Abaixo da Curva de progressoo da Doença (AACPD)\nCriando uma nova variável na planilha (chamada AACPD). Então, pode-se calcular a anova a partir dessa variável (AACPD).\n\nlibrary(epifitter)\ncurve2 &lt;- curve |&gt;\n  group_by(Irrigation, rep) |&gt;\n  summarise(aacpd = AUDPC(day,severity))\n\nm_curve &lt;- lm(aacpd ~Irrigation + factor(rep),\n              data = curve2)\n\nanova(m_curve) \n\nAnalysis of Variance Table\n\nResponse: aacpd\n            Df  Sum Sq  Mean Sq F value  Pr(&gt;F)  \nIrrigation   1 0.23602 0.236017  10.605 0.08275 .\nfactor(rep)  2 0.61291 0.306454  13.771 0.06770 .\nResiduals    2 0.04451 0.022254                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(agricolae)\ncv.model(m_curve)\n\n[1] 1.097572"
  },
  {
    "objectID": "Aula5.html",
    "href": "Aula5.html",
    "title": "Teste T",
    "section": "",
    "text": "Carregamento dos dados a partir da planilha google.\n\nlibrary(gsheet)\n\nmg &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=983033137\")"
  },
  {
    "objectID": "Aula5.html#importando-os-dados",
    "href": "Aula5.html#importando-os-dados",
    "title": "Teste T",
    "section": "",
    "text": "Carregamento dos dados a partir da planilha google.\n\nlibrary(gsheet)\n\nmg &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=983033137\")"
  },
  {
    "objectID": "Aula5.html#visualização-dos-dados",
    "href": "Aula5.html#visualização-dos-dados",
    "title": "Teste T",
    "section": "Visualização dos dados",
    "text": "Visualização dos dados\nO gráfico em Boxplot mostra se a distribuição dos dados se aproxima de uma distribuição normal, o valor das medianas destacadas dentro do box mostra o efeito da distribuíção.\n\nlibrary(tidyverse)\nmg |&gt;\n  ggplot(aes(trat,comp))+\n  geom_boxplot()"
  },
  {
    "objectID": "Aula5.html#teste-t",
    "href": "Aula5.html#teste-t",
    "title": "Teste T",
    "section": "Teste T",
    "text": "Teste T\nPara testar grupos independentes pode-se utilizar o teste T (função t.test). Este é um teste simples, que assume duas premissas: primeira, que a distribuição é normal (pode-se observar pela simetria do box) e segunda, que as variâncias são homogêneas. a função pivot_wider() pode ser usada para passar a planilha do formato largo para o longo.\nO valor do teste T depende da variabilidade dos dados. Quanto mais negativo é o valor de T, menor vai ser o p-valor. O p-valor é o valor da probabilidade dada a hipótese nula de encontrar o valor de uma certa magnitetude.\nNo caso de dados com variâncias homogêneas, adiciona-se o comando var.equal = TRUE (para dados homogêneos é opcional o uso deste comando). Já para variâncias heterogêneas deve-se adicionar o comando var.equal = FALSE (obrigatório).\nApós a análise do teste, deve-se observar se houve diferença estatistíca. De acordo com os resultados btidos deve-se determinar se os resultado do teste T são confiáveis.\nPara obter a confirmação de que a distribuição dos dados é normal pode-se utilizar um teste de normalidade (função shapiro.test())\nO comando report() relata a saida do teste T.\n\nmg2 &lt;- mg |&gt;\n  pivot_wider(names_from = trat,\n              values_from = comp)\nmg2\n\n# A tibble: 10 × 3\n     rep   Mg2 control\n   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1     1   9      13.7\n 2     2  12.5    15.9\n 3     3  10      15.7\n 4     4   8      14.2\n 5     5  13.2    15.9\n 6     6  11      16.5\n 7     7  10.8    18  \n 8     8   9.5    14.4\n 9     9  10.8    16.4\n10    10  10.4    16  \n\nteste1 &lt;- t.test(mg2$control, mg2$Mg2,\n       var.equal = TRUE)\nteste1\n\n\n    Two Sample t-test\n\ndata:  mg2$control and mg2$Mg2\nt = 8.1549, df = 18, p-value = 1.863e-07\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 3.829161 6.486839\nsample estimates:\nmean of x mean of y \n   15.678    10.520 \n\nshapiro.test(mg2$control)\n\n\n    Shapiro-Wilk normality test\n\ndata:  mg2$control\nW = 0.93886, p-value = 0.5404\n\nshapiro.test(mg2$Mg2)\n\n\n    Shapiro-Wilk normality test\n\ndata:  mg2$Mg2\nW = 0.97269, p-value = 0.9146\n\nhist(mg2$control)\n\n\n\nhist(mg2$Mg2)\n\n\n\nvar.test(mg2$control, mg2$Mg2)\n\n\n    F test to compare two variances\n\ndata:  mg2$control and mg2$Mg2\nF = 0.67654, num df = 9, denom df = 9, p-value = 0.5698\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.1680428 2.7237436\nsample estimates:\nratio of variances \n         0.6765394 \n\nqqnorm(mg2$control)\nqqline(mg2$control)\n\n\n\nqqnorm(mg2$Mg2)\nqqline(mg2$Mg2)\n\n\n\nlibrary(report)\nreport(teste1)\n\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Two Sample t-test testing the difference between mg2$control and mg2$Mg2\n(mean of x = 15.68, mean of y = 10.52) suggests that the effect is positive,\nstatistically significant, and large (difference = 5.16, 95% CI [3.83, 6.49],\nt(18) = 8.15, p &lt; .001; Cohen's d = 3.65, 95% CI [2.16, 5.10])\n\n\nPara a comparação dos dados com mais de dois grupos distintos, pode-se utilizar o teste F. Após visualizar os dados no box, pode-se ter a confirmação de que as variâncias são homgenêneas com o test F."
  },
  {
    "objectID": "Aula5.html#dois-grupos-dependentes",
    "href": "Aula5.html#dois-grupos-dependentes",
    "title": "Teste T",
    "section": "Dois grupos dependentes",
    "text": "Dois grupos dependentes\nTeste T para teste pareado com dois grupos (o anterior foi um teste não pareado).\nDados importados:\n\nescala &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1729131173\")\n\nVisualização em boxplot:\n\nescala |&gt;\n  ggplot(aes(assessment,acuracia))+\n  geom_boxplot()\n\n\n\n\nMudança na visualização de dois níveis de um fator do formato longo para o formato largo:\n\nescala2 &lt;- escala |&gt;\n  select(assessment, rater, acuracia) |&gt;\n  pivot_wider(names_from = assessment,\n              values_from = acuracia)\nescala2\n\n# A tibble: 10 × 3\n   rater Unaided Aided1\n   &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n 1 A        0.81   0.91\n 2 B        0.72   0.91\n 3 C        0.4    0.91\n 4 D        0.82   0.96\n 5 E        0.75   0.96\n 6 F        0.45   0.9 \n 7 G        0.81   0.85\n 8 H        0.78   0.88\n 9 I        0.78   0.95\n10 J        0.5    0.94\n\n\n\nshapiro.test(escala2$Unaided)\n\n\n    Shapiro-Wilk normality test\n\ndata:  escala2$Unaided\nW = 0.7748, p-value = 0.007155\n\nshapiro.test(escala2$Aided1)\n\n\n    Shapiro-Wilk normality test\n\ndata:  escala2$Aided1\nW = 0.92852, p-value = 0.4335\n\nvar.test(escala2$Unaided,escala2$Aided1)\n\n\n    F test to compare two variances\n\ndata:  escala2$Unaided and escala2$Aided1\nF = 20.978, num df = 9, denom df = 9, p-value = 0.000106\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n  5.210754 84.459185\nsample estimates:\nratio of variances \n          20.97847 \n\nteste1 &lt;- t.test(escala2$Aided1, escala2$Unaided,\n                 paired = TRUE,\n                 var.equal = FALSE)\nteste1\n\n\n    Paired t-test\n\ndata:  escala2$Aided1 and escala2$Unaided\nt = 4.4214, df = 9, p-value = 0.001668\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.1147647 0.3552353\nsample estimates:\nmean difference \n          0.235 \n\n\nPode-se observar no exemplo utilizando a função var.test, pelo teste F que a hipóte nula (médias são iguais) foi rejeitada. Assim, houve efeito do uso da escala diagramática pelos avaliadores."
  },
  {
    "objectID": "Aula5.html#teste-não-paramétrico",
    "href": "Aula5.html#teste-não-paramétrico",
    "title": "Teste T",
    "section": "Teste não Paramétrico",
    "text": "Teste não Paramétrico\nUm teste não paramétrico podem ser usados quando os dados não seguem uma distribuição normal.\nA função wilcox.test() é uma alternativa não paramétrica a função t.teste (Teste t de Student).\n\nwilcox.test(escala2$Aided1,\n            escala2$Unaided,\n            paired = TRUE)\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  escala2$Aided1 and escala2$Unaided\nV = 55, p-value = 0.005889\nalternative hypothesis: true location shift is not equal to 0"
  },
  {
    "objectID": "Aula12.html",
    "href": "Aula12.html",
    "title": "Análise de correlação",
    "section": "",
    "text": "A correlação é a associação entre duas variáveis respostas diferentes(força e direção de associação entre as duas).Pode haver uma relação de causa e efeito, exemplo: o aumento de uma pode causar a redução de outra. Isso mostra que as variáveis estão positivamente correlacionadas. Também podem estar positivamente relacionadas, quando as duas variáveis aumentam.\nAs relações que nao tem causa e efeito, significa que uma variável não interfere na outra.\nO p-valor baixo vai indicar que indicar uma correlação maior entre as variáveis e o R² quanto de x que interfere no Y.\n\nlibrary(gsheet)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tidyverse)\nimgs &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=373270992\")\n\n\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(MASS)\nlibrary(dplyr)\n\nimgs |&gt;\n  pivot_longer(3:5, names_to = \"method\",\n               values_to = \"value\") |&gt;\n  ggplot(aes(method, value))+\n  geom_boxplot()\n\n\n\nimgs|&gt;\n  ggplot(aes(Assess, ImageJ))+\n  geom_point()+\n  geom_smooth(method = \"lm\")\n\n\n\nimgs2 &lt;- imgs %&gt;% dplyr::select(3:5)\n\nlibrary(AgroR)\ncorgraph(imgs2)\n\n        Var1       Var2       cor            p\n2 LeafDoctor     Assess 0.9666367 5.972544e-42\n3     ImageJ     Assess 0.9776918 8.143613e-48\n6     ImageJ LeafDoctor 0.9797478 3.144091e-49\n\n\n\n\ncor.test(imgs$Assess, imgs$LeafDoctor)\n\n\n    Pearson's product-moment correlation\n\ndata:  imgs$Assess and imgs$LeafDoctor\nt = 31.119, df = 68, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.9466882 0.9792005\nsample estimates:\n      cor \n0.9666367 \n\ncor(imgs$Assess, imgs$LeafDoctor)\n\n[1] 0.9666367\n\nlibrary(corrplot)\ncor_imgs2 &lt;- cor(imgs2)\ncorrplot(cor_imgs2, method = 'number', type = \"upper\", diag = FALSE)\n\n\n\n\nNo gráfico a cor azul indica que a correlação é mais forte e vermelho baixa correlação.\nA medida mais frequente de correlação é o coeficiente de correlação de Pearson, cujos valores variam de -1 a +1. Valores próximos de +1 indicam uma correlação positiva forte, enquanto valores próximos de -1 indicam uma correlação negativa forte. Valores próximos de zero sugerem uma correlação fraca ou inexistente.\n\nlibrary(AgroR)\n\ncampo &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=866852711\")\n\ncampo2 &lt;- campo |&gt;\n dplyr::select(DFC, FER, PROD)\ncorgraph(campo2)\n\n  Var1 Var2        cor            p\n2  FER  DFC  0.9316978 9.864101e-15\n3 PROD  DFC -0.6928161 1.110652e-05\n6 PROD  FER -0.6258321 1.277444e-04\n\n\n\n\ncampo |&gt;\n  ggplot(aes(DFC, PROD))+\n  geom_point()"
  },
  {
    "objectID": "Aula10.html",
    "href": "Aula10.html",
    "title": "ANOVA com parcela subdividida",
    "section": "",
    "text": "A ANOVA para parcelas subdivididas é uma técnica estatística usada em experimentos onde existem duas ou mais fontes de variabilidade que estão hierarquicamente estruturadas. Pode-se ter diferentes tratamentos aplicados a parcelas principais e subparcelas dentro dessas parcelas principais recebendo diferentes tratamentos adicionais."
  },
  {
    "objectID": "Aula10.html#carregando-os-dados",
    "href": "Aula10.html#carregando-os-dados",
    "title": "ANOVA com parcela subdividida",
    "section": "Carregando os dados",
    "text": "Carregando os dados\n\nlibrary(gsheet)\nmilho &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=1345524759\")"
  },
  {
    "objectID": "Aula10.html#visualização-da-variável-index",
    "href": "Aula10.html#visualização-da-variável-index",
    "title": "ANOVA com parcela subdividida",
    "section": "Visualização da variável Index",
    "text": "Visualização da variável Index\n\nlibrary(tidyverse)\nlibrary (ggplot2)\n\nmilho |&gt;\n  ggplot(aes(method, index))+\n  geom_jitter(width=0.1, alpha = 0.2)+\n  facet_wrap(~hybrid)+\n  stat_summary(fun.data = \n                 \"mean_cl_boot\", size=0.5, color=\n                 \"blue\")"
  },
  {
    "objectID": "Aula10.html#anova-para-parcela-subdividida",
    "href": "Aula10.html#anova-para-parcela-subdividida",
    "title": "ANOVA com parcela subdividida",
    "section": "Anova para parcela subdividida",
    "text": "Anova para parcela subdividida\n\nlibrary(dplyr)\nlibrary(lme4)\nlibrary(car)\n\nmilho &lt;- milho |&gt;\n  mutate(block = as.factor(block))\n\nmix2 &lt;- lmer(sqrt(index) ~ hybrid*method + block +\n               (1|block/hybrid), data = milho)\nAnova(mix2)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: sqrt(index)\n                Chisq Df Pr(&gt;Chisq)   \nhybrid        15.3159  5   0.009095 **\nmethod         3.8886  1   0.048615 * \nblock          0.0718  3   0.994997   \nhybrid:method 13.3812  5   0.020057 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(performance)\ncheck_normality(mix2)\n\nOK: residuals appear as normally distributed (p = 0.440).\n\ncheck_heteroscedasticity(mix2)\n\nOK: Error variance appears to be homoscedastic (p = 0.971).\n\nlibrary(DHARMa)\nplot(simulateResiduals(mix2))\n\n\n\nqqnorm(residuals(mix2))\nqqline(residuals(mix2))\n\n\n\nhist(residuals(mix2))\n\n\n\nlibrary(emmeans)\nmedias_milho &lt;- emmeans(mix2,\n                        ~hybrid | method,\n                        type = \"response\")\nmedias_milho2 &lt;- emmeans(mix2,\n                        ~method | hybrid,\n                         type = \"response\")\n\nlibrary (multcomp)\ncld(medias_milho, Letters = LETTERS)\n\nmethod = pin:\n hybrid   response   SE   df lower.CL upper.CL .group\n BG7049H      19.4 10.7 6084     4.10     46.0  A    \n 30K64        20.3 10.9 6084     4.51     47.4  A    \n 30F53 YH     24.5 12.0 6084     6.61     53.7  AB   \n 30F53 HX     25.0 12.1 6084     6.84     54.4  AB   \n 30S31YH      31.7 13.7 6084    10.57     64.2  AB   \n 30S31H       37.1 14.8 6084    13.79     71.8   B   \n\nmethod = silk:\n hybrid   response   SE   df lower.CL upper.CL .group\n BG7049H      19.1 10.6 6084     3.96     45.6  A    \n 30K64        21.3 11.2 6084     5.00     48.9  A    \n 30F53 HX     24.4 12.0 6084     6.56     53.6  A    \n 30F53 YH     26.0 12.4 6084     7.42     56.0  A    \n 30S31H       26.3 12.5 6084     7.57     56.4  A    \n 30S31YH      26.4 12.5 6084     7.62     56.5  A    \n\nResults are averaged over the levels of: block \nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nDe acordo com o quado da anova pode-se observar que há interação entre hibrido e o método utilizado, ou seja, de acordo com essa interação o valor de index muda. Caso nao desse significativo poderia-se analisar o p-valor em isolado (tratamneto, bloco, etc.)\nTambém pode-se observar que teve diferença entre o método Pin e Silk no hibrido 4, o método teve efeito. Houve variabilidade (a observação pode ser feita em cada método). Obs.: letras maiusculas comparam na coluna, minuscula na linha (% de significancia pelo teste de tukey).\n\nmix3 &lt;- lmer(sqrt(yield) ~ hybrid*method + block +\n               (1|block/hybrid), data = milho)\nAnova(mix3)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: sqrt(yield)\n                Chisq Df Pr(&gt;Chisq)    \nhybrid        25.5591  5  0.0001086 ***\nmethod         0.0520  1  0.8196750    \nblock          2.3606  3  0.5010021    \nhybrid:method 24.4985  5  0.0001741 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ncheck_normality(mix3)\n\nOK: residuals appear as normally distributed (p = 0.214).\n\ncheck_heteroscedasticity(mix3)\n\nOK: Error variance appears to be homoscedastic (p = 0.686)."
  },
  {
    "objectID": "Aula11.html",
    "href": "Aula11.html",
    "title": "Regressão linear",
    "section": "",
    "text": "Para dados quantitativos, a análise de regressão costuma ser mais adequada do que a análise de variância. A regressão permite modelar e prever a relação entre uma variável dependente e uma ou mais variáveis independentes."
  },
  {
    "objectID": "Aula11.html#regressão-linear-simples",
    "href": "Aula11.html#regressão-linear-simples",
    "title": "Regressão linear",
    "section": "Regressão linear simples",
    "text": "Regressão linear simples\nNa regressão linear simples determina-se uma linha reta que melhor represente essa relação, permitindo prever valores da variável dependente a partir dos valores da variável independente."
  },
  {
    "objectID": "Aula11.html#carregando-a-planilha",
    "href": "Aula11.html#carregando-a-planilha",
    "title": "Regressão linear",
    "section": "Carregando a planilha",
    "text": "Carregando a planilha\n\nlibrary(gsheet)\nestande &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=401662555\")"
  },
  {
    "objectID": "Aula11.html#visualização",
    "href": "Aula11.html#visualização",
    "title": "Regressão linear",
    "section": "Visualização",
    "text": "Visualização\nO geom_jitter() forma o gráfico de dispersão. Visualização da média e os intervalos de confiança dos dados.\n\nlibrary(ggplot2)\nm1 &lt;- estande |&gt;\n  ggplot(aes(trat, nplants))+\n         geom_jitter(width = 0.1, alpha = 0.2)+\n         #facet_wrap(~ trat)+\n         stat_summary(fun.data = \n                 \"mean_cl_boot\", size= 0.5, color=\n                 \"blue\")\nm1"
  },
  {
    "objectID": "Aula11.html#analisando-cada-experimento-isoladamente",
    "href": "Aula11.html#analisando-cada-experimento-isoladamente",
    "title": "Regressão linear",
    "section": "Analisando cada experimento isoladamente",
    "text": "Analisando cada experimento isoladamente\nA regressão linear precisa definir um modelo que melhor se ajuste a curva ou linha de resposta. Portanto, deve-se fazer a análise para cada experimento ou analisar em grupos (modelos mistos).\nA função geom_smooth(se = F, method = lm) permite adicionar uma linha de regressão linear sem intervalo de confiança.\nExperimento 1\nR² mostra a relação entre a reta e os pontos que estão sendo observados (relação entre váriavel dependente e independente). O R² varia de 0 a 1.\nQuanto mais próximo de 1 o valor do R², maior é a proporção da variabilidade na variável dependente que pode ser explicada pelo modelo de regressão. R² mais próximo de 0 indica que o modelo explica uma menor proporção da variabilidade na variável dependente.\n\nlibrary(dplyr)\nexp1 &lt;- estande |&gt; \n  filter(exp == 1)\n\nexp1 |&gt;\n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  ylim(0,100)+\n  geom_smooth(se = F, method = lm)\n\n\n\nlm1 &lt;- lm(nplants ~trat,\n          data = exp1)\nsummary(lm1)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.500  -6.532   1.758   8.573  27.226 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  52.5000     4.2044  12.487 1.84e-11 ***\ntrat         -0.2419     0.1859  -1.301    0.207    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15 on 22 degrees of freedom\nMultiple R-squared:  0.07148,   Adjusted R-squared:  0.02928 \nF-statistic: 1.694 on 1 and 22 DF,  p-value: 0.2066\n\n\nExperimento 2\n\nexp2 &lt;- estande |&gt; \n  filter(exp == 2)\n\nexp2 |&gt; \n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  ylim(0,100)+\n  geom_smooth(method= \"lm\", \n              se=FALSE, \n              formula = y ~poly(x,2), color=\"black\")+\n  geom_smooth(method = \"lm\",\n              se = FALSE)\n\n\n\n# modelo linear\n\nexp2$trat2 &lt;- exp2$trat^2 \n  \n# primeira ordem\nlm2 &lt;- lm(nplants ~ trat, \n          data = exp2)\n# segunda ordem ou quadrático\nlm3 &lt;- lm(nplants ~ trat + trat2 , \n          data = exp2)\n\nsummary(lm2)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.7816  -7.7150   0.5653   8.1929  19.2184 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  60.9857     3.6304  16.798 4.93e-14 ***\ntrat         -0.7007     0.1605  -4.365 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.95 on 22 degrees of freedom\nMultiple R-squared:  0.4641,    Adjusted R-squared:  0.4398 \nF-statistic: 19.05 on 1 and 22 DF,  p-value: 0.0002473\n\nsummary(lm3)\n\n\nCall:\nlm(formula = nplants ~ trat + trat2, data = exp2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.439  -6.019   1.789   8.016  19.561 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 66.30156    4.42097  14.997 1.08e-12 ***\ntrat        -1.77720    0.58467  -3.040  0.00623 ** \ntrat2        0.02223    0.01166   1.906  0.07036 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.24 on 21 degrees of freedom\nMultiple R-squared:  0.5432,    Adjusted R-squared:  0.4997 \nF-statistic: 12.49 on 2 and 21 DF,  p-value: 0.0002675\n\nAIC(lm2)\n\n[1] 194.9597\n\nAIC(lm3)\n\n[1] 193.1284\n\n\nExperimento 3\n\nexp3 &lt;- estande |&gt;\n  filter(exp==3)\n\nexp3 |&gt;\n  ggplot(aes(trat, nplants))+\n  geom_point()+\n  ylim(0,100)+\n  geom_smooth(se = F, method = lm)\n\n\n\nexp3\n\n# A tibble: 24 × 4\n     exp  trat bloco nplants\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1     3     0     1     101\n 2     3     0     2      94\n 3     3     0     3      93\n 4     3     0     4     105\n 5     3     3     1      93\n 6     3     3     2      97\n 7     3     3     3      96\n 8     3     3     4     109\n 9     3     6     1      99\n10     3     6     2      95\n# ℹ 14 more rows\n\n#modelo linear\nlm3 &lt;- lm(nplants ~trat,\n          data = exp3)\nsummary(lm3)\n\n\nCall:\nlm(formula = nplants ~ trat, data = exp3)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.5887  -3.9597   0.7177   5.5806  19.8952 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  95.7500     2.9529  32.425  &lt; 2e-16 ***\ntrat         -0.7634     0.1306  -5.847 6.97e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.53 on 22 degrees of freedom\nMultiple R-squared:  0.6085,    Adjusted R-squared:  0.5907 \nF-statistic: 34.19 on 1 and 22 DF,  p-value: 6.968e-06"
  },
  {
    "objectID": "Aula11.html#modelo-glm",
    "href": "Aula11.html#modelo-glm",
    "title": "Regressão linear",
    "section": "Modelo GLM",
    "text": "Modelo GLM\nO Modelo Linear Generalizado (GLM) representa uma alternativa ao modelo linear convencional, sendo uma extensão que oferece flexibilidade para lidar com diversos tipos de variáveis resposta(categóricas ou contínuas). o GLM também permite modelar relações não-lineares entre a variável resposta e as variáveis explicativas.\n\nglm1 &lt;- glm(nplants ~ trat, family = \"gaussian\", data = exp1)\n\nsummary(glm1)\n\n\nCall:\nglm(formula = nplants ~ trat, family = \"gaussian\", data = exp1)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  52.5000     4.2044  12.487 1.84e-11 ***\ntrat         -0.2419     0.1859  -1.301    0.207    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 224.9751)\n\n    Null deviance: 5330.5  on 23  degrees of freedom\nResidual deviance: 4949.5  on 22  degrees of freedom\nAIC: 202\n\nNumber of Fisher Scoring iterations: 2\n\nglm1b &lt;- glm(nplants ~trat, family = \"poisson\",\n             data = exp1)\nsummary(glm1b)\n\n\nCall:\nglm(formula = nplants ~ trat, family = \"poisson\", data = exp1)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  3.963738   0.039359 100.708  &lt; 2e-16 ***\ntrat        -0.005199   0.001862  -2.793  0.00523 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 111.37  on 23  degrees of freedom\nResidual deviance: 103.31  on 22  degrees of freedom\nAIC: 243.58\n\nNumber of Fisher Scoring iterations: 4\n\nAIC(glm1b)\n\n[1] 243.5839\n\nglm2 &lt;- glm(nplants ~ trat, family = \"gaussian\", data = exp1)\n\nsummary(glm2)\n\n\nCall:\nglm(formula = nplants ~ trat, family = \"gaussian\", data = exp1)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  52.5000     4.2044  12.487 1.84e-11 ***\ntrat         -0.2419     0.1859  -1.301    0.207    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 224.9751)\n\n    Null deviance: 5330.5  on 23  degrees of freedom\nResidual deviance: 4949.5  on 22  degrees of freedom\nAIC: 202\n\nNumber of Fisher Scoring iterations: 2\n\nglm2b &lt;- glm(nplants ~trat, family = \"poisson\",\n             data = exp2)\nsummary(glm2b)\n\n\nCall:\nglm(formula = nplants ~ trat, family = \"poisson\", data = exp2)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  4.134189   0.037583 110.003  &lt; 2e-16 ***\ntrat        -0.016270   0.002059  -7.901 2.76e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 139.783  on 23  degrees of freedom\nResidual deviance:  69.578  on 22  degrees of freedom\nAIC: 210.24\n\nNumber of Fisher Scoring iterations: 4\n\nAIC(glm2b)\n\n[1] 210.2353\n\nglm3 &lt;- glm(nplants ~ trat + (trat| exp), family = \"gaussian\", data = exp1)\n\nsummary(glm3)\n\n\nCall:\nglm(formula = nplants ~ trat + (trat | exp), family = \"gaussian\", \n    data = exp1)\n\nCoefficients: (1 not defined because of singularities)\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     52.5000     4.2044  12.487 1.84e-11 ***\ntrat            -0.2419     0.1859  -1.301    0.207    \ntrat | expTRUE       NA         NA      NA       NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 224.9751)\n\n    Null deviance: 5330.5  on 23  degrees of freedom\nResidual deviance: 4949.5  on 22  degrees of freedom\nAIC: 202\n\nNumber of Fisher Scoring iterations: 2\n\nAIC(glm3)\n\n[1] 202.0045\n\nglm3b &lt;- glm(nplants ~trat + (trat| exp), family = \"poisson\",\n             data = exp3)\nsummary(glm3b)\n\n\nCall:\nglm(formula = nplants ~ trat + (trat | exp), family = \"poisson\", \n    data = exp3)\n\nCoefficients: (1 not defined because of singularities)\n                Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)     4.571590   0.029539 154.762  &lt; 2e-16 ***\ntrat           -0.009965   0.001488  -6.697 2.13e-11 ***\ntrat | expTRUE        NA         NA      NA       NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 77.906  on 23  degrees of freedom\nResidual deviance: 29.952  on 22  degrees of freedom\nAIC: 183.93\n\nNumber of Fisher Scoring iterations: 4\n\nAIC(glm3b)\n\n[1] 183.9324"
  },
  {
    "objectID": "Aula11.html#modelo-misto",
    "href": "Aula11.html#modelo-misto",
    "title": "Regressão linear",
    "section": "Modelo misto",
    "text": "Modelo misto\nModelo que permite que as observações sejam divididas em grupos ou subgrupos.\n\nlibrary(remotes)\n##remotes::install_github(\"emdelponte/r4pde\", force = TRUE)\n\nlibrary(r4pde)\nwr &lt;- WhiteMoldSoybean\n\n\nwr |&gt; \n  ggplot(aes(inc, yld, group = factor(study)))+\n  geom_point()+\n  facet_wrap(~ study)+\n  geom_smooth(method = \"lm\", se = F)+\n  theme_minimal()\n\n\n\nmofo1 &lt;- lm(yld ~inc,\n            data = wr)\nsummary(mofo1)\n\n\nCall:\nlm(formula = yld ~ inc, data = wr)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1657.85  -594.50   -91.32   531.76  1693.15 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 3299.619     56.451  58.451  &lt; 2e-16 ***\ninc           -9.261      2.108  -4.393 1.45e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 745.8 on 380 degrees of freedom\nMultiple R-squared:  0.04833,   Adjusted R-squared:  0.04582 \nF-statistic:  19.3 on 1 and 380 DF,  p-value: 1.452e-05\n\n\n\nlibrary(broom)\nmofo2 &lt;- wr |&gt;\n  group_by(study)|&gt;\n  do(tidy(lm(.$yld~.$inc), conf.int=TRUE))\nmofo2\n\n# A tibble: 70 × 8\n# Groups:   study [35]\n   study term        estimate std.error statistic  p.value conf.low conf.high\n   &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1     1 (Intercept)  3329.       86.8      38.3  4.60e-13   3138.    3520.  \n 2     1 .$inc         -14.2       2.08     -6.85 2.78e- 5    -18.8     -9.64\n 3     2 (Intercept)  2682.       48.6      55.2  8.55e-15   2575.    2789.  \n 4     2 .$inc          -6.93      1.49     -4.66 6.89e- 4    -10.2     -3.66\n 5     3 (Intercept)  4017.       61.6      65.2  1.37e-15   3882.    4153.  \n 6     3 .$inc         -18.6       1.71    -10.9  3.11e- 7    -22.4    -14.9 \n 7     4 (Intercept)  2814.      151.       18.6  1.15e- 9   2481.    3147.  \n 8     4 .$inc         -43.5      16.8      -2.58 2.56e- 2    -80.5     -6.38\n 9     5 (Intercept)  3317.      234.       14.2  2.07e- 8   2802.    3832.  \n10     5 .$inc         -21.2       5.69     -3.72 3.36e- 3    -33.7     -8.67\n# ℹ 60 more rows\n\ndf &lt;- mofo2 |&gt; filter(term == \".$inc\")\nmean(df$estimate)\n\n[1] -19.52932\n\nfit_all &lt;- wr%&gt;%\n  group_by(study) |&gt; \n  do(broom::tidy(lm(.$yld ~ .$inc), conf.int=TRUE))\nfit_all\n\n# A tibble: 70 × 8\n# Groups:   study [35]\n   study term        estimate std.error statistic  p.value conf.low conf.high\n   &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1     1 (Intercept)  3329.       86.8      38.3  4.60e-13   3138.    3520.  \n 2     1 .$inc         -14.2       2.08     -6.85 2.78e- 5    -18.8     -9.64\n 3     2 (Intercept)  2682.       48.6      55.2  8.55e-15   2575.    2789.  \n 4     2 .$inc          -6.93      1.49     -4.66 6.89e- 4    -10.2     -3.66\n 5     3 (Intercept)  4017.       61.6      65.2  1.37e-15   3882.    4153.  \n 6     3 .$inc         -18.6       1.71    -10.9  3.11e- 7    -22.4    -14.9 \n 7     4 (Intercept)  2814.      151.       18.6  1.15e- 9   2481.    3147.  \n 8     4 .$inc         -43.5      16.8      -2.58 2.56e- 2    -80.5     -6.38\n 9     5 (Intercept)  3317.      234.       14.2  2.07e- 8   2802.    3832.  \n10     5 .$inc         -21.2       5.69     -3.72 3.36e- 3    -33.7     -8.67\n# ℹ 60 more rows\n\np3 &lt;- fit_all |&gt; \n  filter(term == \"(Intercept)\") |&gt; \n  ggplot(aes(x = estimate))+\n  geom_histogram(bins = 8, color = \"white\", fill = \"gray50\")+\n  theme_r4pde()+\n  labs(x = \"Intercept\", y = \"Frequency\")\n\np4 &lt;- fit_all |&gt; \n  filter(term == \".$inc\") |&gt; \n  ggplot(aes(x = estimate))+\n  geom_histogram(bins = 8, color = \"white\", fill = \"gray50\")+\n  theme_r4pde()+\n  labs(x = \"Slope\", y = \"Frequency\")\n\n\nlibrary(patchwork)\np3 | p4"
  },
  {
    "objectID": "Aula13.html",
    "href": "Aula13.html",
    "title": "Regressão não-linear",
    "section": "",
    "text": "A regressão não-linear é usada quando a relação entre as variáveis independentes e dependentes não pode ser modelada por uma função linear.\nO pacote drc permite ajustar modelos de regressão dose-resposta e realizar análises estatísticas, ou seja, permite ajustar curvas de dose-resposta dos dados. Esse pacote também fornece funções para calcular estimativas de EC50 (qual valor de X reduziu em 50% o valor de Y).\nOutro pacote que permite calcular o valor de EC50 é o ec50estimator.\n\nlibrary(gsheet)\nlibrary(ggplot2)\nlibrary(tidyverse)\n\npyra &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=465348652\")\n\npyra2 &lt;- pyra |&gt; \n  group_by(code, state, dose) |&gt; \n  summarise(mean_germination = mean(germination)) \n\npyra2|&gt; \n  ggplot(aes(dose, mean_germination))+\n  geom_point()+\n  facet_wrap(~code)\n\n\n\nlibrary(drc)\n\nisolado165 &lt;- pyra2 |&gt; \n  filter(code == \"186\")\n\ndrc1 &lt;- drm(mean_germination ~ dose, data = isolado165,\n            fct = W1.3())\nAIC(drc1)\n\n[1] 20.97861\n\nplot(drc1)\n\n\n\nED(drc1, 50, interval = \"delta\")\n\n\nEstimated effective doses\n\n       Estimate Std. Error    Lower    Upper\ne:1:50 0.612064   0.015429 0.562963 0.661165\n\nsummary(drc1)\n\n\nModel fitted: Weibull (type 1) with lower limit at 0 (3 parms)\n\nParameter estimates:\n\n               Estimate Std. Error t-value   p-value    \nb:(Intercept)  2.832159   0.213496  13.266 0.0009257 ***\nd:(Intercept) 48.767893   0.716131  68.099 6.978e-06 ***\ne:(Intercept)  0.696626   0.018156  38.368 3.895e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error:\n\n 1.009228 (3 degrees of freedom)\n\nlibrary(ec50estimator)\ndf_ec50 &lt;- estimate_EC50(mean_germination ~ dose,\n                         data = pyra2,\n                         isolate_col = \"code\",\n                         interval = \"delta\",\n                         fct = drc::LL.3())\n\ndf_ec50 |&gt; \n  ggplot(aes(reorder(ID, Estimate), Estimate))+\n  geom_point()+\n  geom_errorbar(aes(ymin = Lower, ymax = Upper), width = 0.1)+\n  coord_flip()"
  },
  {
    "objectID": "Aula6.html",
    "href": "Aula6.html",
    "title": "Anova com um fator",
    "section": "",
    "text": "library(gsheet)\nmicelial &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=959387827\")\n\n\nlibrary(ggplot2)\nmicelial |&gt;\n  ggplot(aes(especie, tcm))+\n  geom_jitter()\n\n\n\n\nA função anova() permite a observação da variabilidade em cada grupo.\nO bartlett.test() é um teste estatístico utilizado para verificar se múltiplas amostras independentes possuem variâncias homogêneas.\n\nm1 &lt;- lm(tcm ~ especie -1, data = micelial)\n\nanova(m1)\n\nAnalysis of Variance Table\n\nResponse: tcm\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nespecie    5 51.677 10.3354   552.2 &lt; 2.2e-16 ***\nResiduals 25  0.468  0.0187                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(m1)\n\n\nCall:\nlm(formula = tcm ~ especie - 1, data = micelial)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.23667 -0.09667  0.01583  0.08833  0.28333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \nespecieFasi  1.57167    0.05585   28.14  &lt; 2e-16 ***\nespecieFaus  1.23667    0.05585   22.14  &lt; 2e-16 ***\nespecieFcor  1.32167    0.05585   23.66  &lt; 2e-16 ***\nespecieFgra  0.91167    0.05585   16.32 7.66e-15 ***\nespecieFmer  1.42667    0.05585   25.54  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1368 on 25 degrees of freedom\nMultiple R-squared:  0.991, Adjusted R-squared:  0.9892 \nF-statistic: 552.2 on 5 and 25 DF,  p-value: &lt; 2.2e-16\n\nshapiro.test(m1$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m1$residuals\nW = 0.9821, p-value = 0.8782\n\nbartlett.test(tcm ~especie, data = micelial)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  tcm by especie\nBartlett's K-squared = 4.4367, df = 4, p-value = 0.3501\n\nlibrary(emmeans)\nmedias1 &lt;- emmeans(m1, ~ especie)\n\nlibrary(multcomp)\nlibrary(multcompView)\ncld(medias1)\n\n especie emmean     SE df lower.CL upper.CL .group\n Fgra     0.912 0.0559 25    0.797     1.03  1    \n Faus     1.237 0.0559 25    1.122     1.35   2   \n Fcor     1.322 0.0559 25    1.207     1.44   2   \n Fmer     1.427 0.0559 25    1.312     1.54   23  \n Fasi     1.572 0.0559 25    1.457     1.69    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 5 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\nlibrary(DHARMa)\nplot(simulateResiduals(m1))\n\n\n\nlibrary(performance)\ncheck_normality(m1)\n\nOK: residuals appear as normally distributed (p = 0.878).\n\ncheck_heteroscedasticity(m1)\n\nOK: Error variance appears to be homoscedastic (p = 0.880).\n\ncheck_model(m1)\n\n\n\n\nUsa-se a função count() para fazer a contagem do número de repetições (n), contagem dos insetos mortos devido a condição inseticida. Os dados apresentam apenas um fator, portanto faz-se uma anova unifatorial.\n\nlibrary (ggplot2)\n\ntheme_set(theme_bw())\n\ninseticida &lt;- InsectSprays\nlibrary(tidyverse)\ninseticida |&gt;\n  count(spray)\n\n  spray  n\n1     A 12\n2     B 12\n3     C 12\n4     D 12\n5     E 12\n6     F 12"
  },
  {
    "objectID": "Aula6.html#três-tratamentos-ou-mais",
    "href": "Aula6.html#três-tratamentos-ou-mais",
    "title": "Anova com um fator",
    "section": "",
    "text": "library(gsheet)\nmicelial &lt;- gsheet2tbl(\"https://docs.google.com/spreadsheets/d/1bq2N19DcZdtax2fQW9OHSGMR0X2__Z9T/edit#gid=959387827\")\n\n\nlibrary(ggplot2)\nmicelial |&gt;\n  ggplot(aes(especie, tcm))+\n  geom_jitter()\n\n\n\n\nA função anova() permite a observação da variabilidade em cada grupo.\nO bartlett.test() é um teste estatístico utilizado para verificar se múltiplas amostras independentes possuem variâncias homogêneas.\n\nm1 &lt;- lm(tcm ~ especie -1, data = micelial)\n\nanova(m1)\n\nAnalysis of Variance Table\n\nResponse: tcm\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nespecie    5 51.677 10.3354   552.2 &lt; 2.2e-16 ***\nResiduals 25  0.468  0.0187                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(m1)\n\n\nCall:\nlm(formula = tcm ~ especie - 1, data = micelial)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.23667 -0.09667  0.01583  0.08833  0.28333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \nespecieFasi  1.57167    0.05585   28.14  &lt; 2e-16 ***\nespecieFaus  1.23667    0.05585   22.14  &lt; 2e-16 ***\nespecieFcor  1.32167    0.05585   23.66  &lt; 2e-16 ***\nespecieFgra  0.91167    0.05585   16.32 7.66e-15 ***\nespecieFmer  1.42667    0.05585   25.54  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1368 on 25 degrees of freedom\nMultiple R-squared:  0.991, Adjusted R-squared:  0.9892 \nF-statistic: 552.2 on 5 and 25 DF,  p-value: &lt; 2.2e-16\n\nshapiro.test(m1$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m1$residuals\nW = 0.9821, p-value = 0.8782\n\nbartlett.test(tcm ~especie, data = micelial)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  tcm by especie\nBartlett's K-squared = 4.4367, df = 4, p-value = 0.3501\n\nlibrary(emmeans)\nmedias1 &lt;- emmeans(m1, ~ especie)\n\nlibrary(multcomp)\nlibrary(multcompView)\ncld(medias1)\n\n especie emmean     SE df lower.CL upper.CL .group\n Fgra     0.912 0.0559 25    0.797     1.03  1    \n Faus     1.237 0.0559 25    1.122     1.35   2   \n Fcor     1.322 0.0559 25    1.207     1.44   2   \n Fmer     1.427 0.0559 25    1.312     1.54   23  \n Fasi     1.572 0.0559 25    1.457     1.69    3  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 5 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\nlibrary(DHARMa)\nplot(simulateResiduals(m1))\n\n\n\nlibrary(performance)\ncheck_normality(m1)\n\nOK: residuals appear as normally distributed (p = 0.878).\n\ncheck_heteroscedasticity(m1)\n\nOK: Error variance appears to be homoscedastic (p = 0.880).\n\ncheck_model(m1)\n\n\n\n\nUsa-se a função count() para fazer a contagem do número de repetições (n), contagem dos insetos mortos devido a condição inseticida. Os dados apresentam apenas um fator, portanto faz-se uma anova unifatorial.\n\nlibrary (ggplot2)\n\ntheme_set(theme_bw())\n\ninseticida &lt;- InsectSprays\nlibrary(tidyverse)\ninseticida |&gt;\n  count(spray)\n\n  spray  n\n1     A 12\n2     B 12\n3     C 12\n4     D 12\n5     E 12\n6     F 12"
  },
  {
    "objectID": "Aula6.html#visualização-dos-dados",
    "href": "Aula6.html#visualização-dos-dados",
    "title": "Anova com um fator",
    "section": "Visualização dos dados",
    "text": "Visualização dos dados\n\ninseticida |&gt;\n  ggplot(aes(spray, count))+\n  geom_boxplot()\n\n\n\n\nPode-se observar pelo gráfico boxplot gerado, que o eixo y mostra a contagem do número de insetos mortos, que há variabilidade, o spray F apresenta maior variância entre o grupo e o spray E menor variância. Também, pode-se observar outliers nos grupos C e D.\n\nm1 &lt;- lm(count~spray,\n         data = inseticida)\nsummary(m1)\n\n\nCall:\nlm(formula = count ~ spray, data = inseticida)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-8.333 -1.958 -0.500  1.667  9.333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  14.5000     1.1322  12.807  &lt; 2e-16 ***\nsprayB        0.8333     1.6011   0.520    0.604    \nsprayC      -12.4167     1.6011  -7.755 7.27e-11 ***\nsprayD       -9.5833     1.6011  -5.985 9.82e-08 ***\nsprayE      -11.0000     1.6011  -6.870 2.75e-09 ***\nsprayF        2.1667     1.6011   1.353    0.181    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.922 on 66 degrees of freedom\nMultiple R-squared:  0.7244,    Adjusted R-squared:  0.7036 \nF-statistic:  34.7 on 5 and 66 DF,  p-value: &lt; 2.2e-16\n\nanova(m1)\n\nAnalysis of Variance Table\n\nResponse: count\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nspray      5 2668.8  533.77  34.702 &lt; 2.2e-16 ***\nResiduals 66 1015.2   15.38                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(emmeans)\nm1_medias &lt;- emmeans(m1, ~ spray)\nplot(m1_medias)\n\n\n\nlibrary(multcomp)\ncld(m1_medias)\n\n spray emmean   SE df lower.CL upper.CL .group\n C       2.08 1.13 66   -0.177     4.34  1    \n E       3.50 1.13 66    1.240     5.76  1    \n D       4.92 1.13 66    2.656     7.18  1    \n A      14.50 1.13 66   12.240    16.76   2   \n B      15.33 1.13 66   13.073    17.59   2   \n F      16.67 1.13 66   14.406    18.93   2   \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 6 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\npwpm(m1_medias)\n\n        A       B       C       D       E       F\nA [14.50]  0.9952  &lt;.0001  &lt;.0001  &lt;.0001  0.7542\nB  -0.833 [15.33]  &lt;.0001  &lt;.0001  &lt;.0001  0.9603\nC  12.417  13.250 [ 2.08]  0.4921  0.9489  &lt;.0001\nD   9.583  10.417  -2.833 [ 4.92]  0.9489  &lt;.0001\nE  11.000  11.833  -1.417   1.417 [ 3.50]  &lt;.0001\nF  -2.167  -1.333 -14.583 -11.750 -13.167 [16.67]\n\nRow and column labels: spray\nUpper triangle: P values   adjust = \"tukey\"\nDiagonal: [Estimates] (emmean) \nLower triangle: Comparisons (estimate)   earlier vs. later\n\npwpp(m1_medias)\n\n\n\npairs(m1_medias)\n\n contrast estimate  SE df t.ratio p.value\n A - B      -0.833 1.6 66  -0.520  0.9952\n A - C      12.417 1.6 66   7.755  &lt;.0001\n A - D       9.583 1.6 66   5.985  &lt;.0001\n A - E      11.000 1.6 66   6.870  &lt;.0001\n A - F      -2.167 1.6 66  -1.353  0.7542\n B - C      13.250 1.6 66   8.276  &lt;.0001\n B - D      10.417 1.6 66   6.506  &lt;.0001\n B - E      11.833 1.6 66   7.391  &lt;.0001\n B - F      -1.333 1.6 66  -0.833  0.9603\n C - D      -2.833 1.6 66  -1.770  0.4921\n C - E      -1.417 1.6 66  -0.885  0.9489\n C - F     -14.583 1.6 66  -9.108  &lt;.0001\n D - E       1.417 1.6 66   0.885  0.9489\n D - F     -11.750 1.6 66  -7.339  &lt;.0001\n E - F     -13.167 1.6 66  -8.223  &lt;.0001\n\nP value adjustment: tukey method for comparing a family of 6 estimates \n\nm1$residuals\n\n          1           2           3           4           5           6 \n-4.50000000 -7.50000000  5.50000000 -0.50000000 -0.50000000 -2.50000000 \n          7           8           9          10          11          12 \n-4.50000000  8.50000000  2.50000000  5.50000000 -0.50000000 -1.50000000 \n         13          14          15          16          17          18 \n-4.33333333  1.66666667  5.66666667 -4.33333333  0.66666667 -1.33333333 \n         19          20          21          22          23          24 \n 1.66666667  1.66666667  3.66666667  5.66666667 -8.33333333 -2.33333333 \n         25          26          27          28          29          30 \n-2.08333333 -1.08333333  4.91666667 -0.08333333  0.91666667 -1.08333333 \n         31          32          33          34          35          36 \n-0.08333333 -1.08333333  0.91666667 -2.08333333 -1.08333333  1.91666667 \n         37          38          39          40          41          42 \n-1.91666667  0.08333333  7.08333333  1.08333333 -0.91666667 -1.91666667 \n         43          44          45          46          47          48 \n 0.08333333  0.08333333  0.08333333  0.08333333 -2.91666667 -0.91666667 \n         49          50          51          52          53          54 \n-0.50000000  1.50000000 -0.50000000  1.50000000 -0.50000000  2.50000000 \n         55          56          57          58          59          60 \n-2.50000000 -2.50000000 -0.50000000 -1.50000000  2.50000000  0.50000000 \n         61          62          63          64          65          66 \n-5.66666667 -7.66666667 -1.66666667  5.33333333 -1.66666667 -0.66666667 \n         67          68          69          70          71          72 \n-3.66666667 -6.66666667  9.33333333  9.33333333  7.33333333 -3.66666667 \n\nhist(m1$residuals)\n\n\n\nqqnorm(m1$residuals)\nqqline(m1$residuals)\n\n\n\nshapiro.test(m1$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  m1$residuals\nW = 0.96006, p-value = 0.02226\n\nbartlett.test(count ~spray,\n              data = inseticida)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  count by spray\nBartlett's K-squared = 25.96, df = 5, p-value = 9.085e-05\n\nlibrary(performance)\ncheck_normality(m1)\n\nWarning: Non-normality of residuals detected (p = 0.022).\n\ncheck_heteroscedasticity(m1)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p &lt; .001).\n\nlibrary(DHARMa)\nplot(simulateResiduals(m1))\n\n\n\n\nA função lm() que significa linear model, é usado para modelar dados em uma relação linear entre a variavel dependente (resposta) e independente (tratamento).\n“~” significa em função de.\nA função summary ajuda na visualização dos dados. Observar previamente o erro-padrão, graus de liberdade, estatistica de T, e valor P. A comparação foi em relação ao tratamento A.\nA função anova() apresenta o valor de F que é o teste de análise de variância, vai determinar a variabilidade entre os grupos (se o valor calculado for maior que o tabelado, rejeita-se a hipótese nula de que as médias são iguais(P&lt;0,05)).\nA função emmeans() pode ser utilizada para vizualizar as médias e comparar este valor em cada tratamento. Dentro do pacote multicomp, há a função cld que permite visualizar os tratamentos agrupados de acordo com um teste estatistico (Tukey) no exemplo há 2 grupos formados (C, E e D) e (A, B e F), portanto há diferença entre os tratamentos, como pode-se observar na Anova.\nA função pwpm() mostra a comparação entre as médias dos tratamentos pelo teste de tukey. Triângulo superior mostra o p-valor. A diagonal mostra a média e o triângulo inferior mostra a diferença dos tratamentos em relação a média. A função pairs() também pode ser usada para a visualização dos valores de T e p- valor.\nA função pwpp() mostra a visualização do teste de Tukey em relação aos tratamentos.\nO valor dos resíduos (erro) pode ser visualizado utilizando $ (seleciona uma coluna no conjunto de dados). No exemplo, m1 é o conjunto e residuals é o que se deseja selecionar. Pode-se utilizar a função hist() para visualização a distribuiçõao dos residuos e ver se a mesma se aproxima da distribuição normal.\nAs funções qqnorm(m1$residuals) e qqline() juntas mostram um gráfico com os valores da distribuição dos resíduos em circulos e a reta dos residuos esperados. Essas funções plotam os resíduos simulados do modelo, o que pode ser útil para avaliar a adequação do modelo aos dados.\nA função shapiro.test mostra se a distribuição dos dados é normal (Se o valor estiver abaixo de 0,05 a distribuição não é considerada normal). A função check_normality() também pode ser usada para ver a normalidade dos dados.\nA função bartlett.test() mostra se as variâncias são ou não homogêneas (valor abaixo de 0,05 não é considerado homogênea). A função check_heteroscedasticity() também mostra a homogeneidade das variâncias.\nComo a distribuição do conjunto dos dados não foram normais e as variâncias não foram homogêneas, pode se utilizar alternativas para corrigir a distribuição e homogeneidade dos dados -&gt; Transformação."
  }
]